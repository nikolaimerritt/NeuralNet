<!DOCTYPE html>
<!--[if IE]><![endif]-->
<html>
  
  
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <title>Neural Net Factory </title>
    <meta name="viewport" content="width=device-width">
    <meta name="title" content="Neural Net Factory ">
    <meta name="generator" content="docfx 2.58.4.0">
    
    <link rel="shortcut icon" href="../favicon.ico">
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/night-owl.min.css">
    <link rel="stylesheet" href="../styles/colors.css">
    <link rel="stylesheet" href="../styles/discord.css">
    <link rel="stylesheet" href="../styles/main.css">
    <meta property="docfx:navrel" content="../toc.html">
    <meta property="docfx:tocrel" content="toc.html">
    
    
    
  </head>

  <body>
        <div class="top-navbar">

            <a href="javascript:void(0);" class="burger-icon" onclick="toggleMenu()">
                <svg name="Hamburger" style="vertical-align: middle;" width="24" height="24" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" clip-rule="evenodd" d="M20 6H4V9H20V6ZM4 10.999H20V13.999H4V10.999ZM4 15.999H20V18.999H4V15.999Z"></path></svg>
            </a>

            
            <a class="brand" href="../index.html">
              <img src="../logo.svg" alt="" class="logomark">
              <span class="brand-title"></span>
            </a>
        </div>

        <div class="body-content">

            <div id="blackout" class="blackout" onclick="toggleMenu()"></div>

            <nav id="sidebar" role="navigation">

                <div class="sidebar">
                    
                    
                    
                    
                    <div>
                      
                      <a class="brand" href="../index.html">
                        <img src="../logo.svg" alt="" class="logomark">
                        <span class="brand-title"></span>
                      </a>
                      <div id="navbar">
                    
                      </div>
                    
                    </div>


                    <div class="sidebar-item-separator"></div>

                        
                        <div id="sidetoggle">
                          <div id="sidetoc"></div>
                        </div>

                </div>

                <div class="footer">
                  
                  <span>Generated by <strong>DocFX</strong></span>
                </div>
            </nav>

            <main class="main-panel">

                <div role="main" class="hide-when-search">

                        
                        <div class="subnav navbar navbar-default">
                          <div class="container hide-when-search" id="breadcrumb">
                            <ul class="breadcrumb">
                              <li></li>
                            </ul>
                          </div>
                        </div>

                    <article class="content wrap" id="_content" data-uid="nnet-factory">
<h1 id="neural-net-factory">Neural Net Factory</h1>

<p>The <code>NeuralNetFactory</code> class makes it easy to initialise a <a class="xref" href="neural-net.html">NeuralNet</a> for most practical purposes.</p>
<h2 id="starting-from-scratch">Starting From Scratch</h2>
<p>Here, we will initialise a <a class="xref" href="neural-net.html"><code>NeuralNet</code></a> that is ready to learn how to square numbers, while showing the other options along the way. Our <a class="xref" href="neural-net.html"><code>NeuralNet</code></a>'s input will be a vector containing a single number to square, between -50 and 50. The output will be a vector containing a single number that is, approximately, the input number squared.</p>
<h3 id="layer-structure">Layer Structure</h3>
<p>First, decide on the structure you want your layers to have. This is done by creating a list of <a class="xref" href="neural-layer-config.html">NeuralLayerConfig</a>. For example, to create our &quot;x squared&quot; neural net described <a class="xref" href="neural-net-factory.html#starting-from-scratch">above</a>, we will need the input and output layers to both be of size 1. The rest is up to you, but a good structure to go for is:</p>
<ul>
<li>an input layer of size 1</li>
<li>a hidden layer of size 8, using <a class="xref" href="activation.html#relu-activation">ReLU activation</a></li>
<li>a hidden layer of size 8, using <a class="xref" href="activation.html#relu-activation">ReLU activation</a></li>
<li>an output layer of size 1, using no activation at all (that is, <a class="xref" href="activation.html#identity-activation">identity activation</a>)</li>
</ul>
<p>To do this, create the following list:</p>
<pre><code class="lang-cs">List&lt;NeuralLayerConfig&gt; layerStructure = new () 
{
    new InputLayer(size: 1),
    new HiddenLayer(size: 8, activation: new ReluActivation()),
    new HiddenLayer(size: 8, activation: new ReluActivation()),
    new OutputLayer(size: 1, activation: new IdentityActivation())
};
</code></pre>
<h3 id="gradient-descender">Gradient Descender</h3>
<p>Next, decide on which method of <a class="xref" href="gradient-descender.html">gradient descent</a> you wish to use. <a class="xref" href="gradient-descender.html#adam-gradient-descender">Adam gradient descent</a> with default arguments is reccomended for most training data sets, and is used in this example:</p>
<pre><code class="lang-cs">GradientDescender gradientDescender = new AdamGradientDescender();
</code></pre>
<h3 id="cost-function">Cost Function</h3>
<p>Next, decide on which cost function you wish to use. This will depend heavily on what kind of data you wish to learn. Here, since our outputs lie in a wide range (between -2500 and 2500), <a class="xref" href="cost-function.html#mean-squared-error">mean squared error</a> is used:</p>
<pre><code class="lang-cs">CostFunction cost = new MSECost();
</code></pre>
<h2 id="creating-your-neural-network">Creating your Neural Network</h2>
<p>There are various ways of best initializing a <code>NeuralNet</code>, depending on which activators it will use and what training data it will be learning.</p>
<h3 id="optimising-for-relu-learning">Optimising for ReLU learning</h3>
<p>If your layer structure mostly uses ReLU activation (such as in our example), you can create a Neural Net that is optimised for learning with ReLU:</p>
<pre><code class="lang-cs">NeuralNet neuralNet = NeuralNetFactory.OptimisedForRelu(layerStructure, gradientDescender, cost);
</code></pre>
<p>This is it: our <a class="xref" href="neural-net.html"><code>NeuralNet</code></a> has been created, ready to learn how to square numbers!</p>
<h3 id="optimising-for-tanh-learning">Optimising for tanh learning</h3>
<p>If, however, your layer structure mostly uses tanh activation, you can create a NeuralNet that is optimised for learning with tanh:</p>
<pre><code class="lang-cs">NeuralNet neuralNet = NeuralNetFactory.OptimisedForTanh(layerStructure, gradientDescender, cost);
</code></pre>
<h3 id="optimising-for-learning-a-particular-data-set">Optimising for learning a particular data set</h3>
<p>A more recent option is to create a NeuralNet that is optimised for learning some particular training data. When optimising, this will take into account the NeuralNet's layer structure and activators. However, it will not take into account the gradient descent method or cost function used.</p>
<pre><code class="lang-cs">IEnumerable&lt;(Vector&lt;double&gt; input, Vector&lt;double&gt; desiredOutput)&gt; trainingData = ... ;
NeuralNet neuralNet = NeuralNetFactory.OptimisedForTrainingData(layerStructure, trainingData, gradientDescender, cost);
</code></pre>
<p>Since the method used in <code>NeuralNetFactory.OptimisedForTrainingData()</code> only uses the input vectors in the training data, there is an overload that simply takes the training input vectors:</p>
<pre><code class="lang-cs">IEnumerable&lt;Vector&lt;double&gt;&gt; trainingInputs = ... ;
NeuralNet neuralNet = NeuralNetFactory.OptimisedForTrainingData(layerStructure, trainingInputs, gradientDescender, cost);
</code></pre>
<h2 id="reading-a-neuralnet-from-a-directory">Reading a <code>NeuralNet</code> from a directory</h2>
<p>If you have previously written a NeuralNet to a directory using <code>NeuralNet.WriteToDirectory()</code>, then <code>NeuralNetFactory.ReadFromDirectory()</code> will load the NeuralNet back in. <code>NeuralNet.ReadFromDirectory()</code> returns a new NeuralNet with identical:</p>
<ul>
<li><code>Parameter</code> (so, identical weights, biases and layer structure)</li>
<li><code>Activator</code>s applied to their corresponding layers</li>
<li><code>GradientDescender</code></li>
<li><code>CostFunction</code>
to the original NeuralNet that was written to the directory:</li>
</ul>
<pre><code class="lang-cs">NeuralNet neuralNet = ... ;
neuralNet.Fit(...);
neuralNet.WriteToDirectory(&quot;../../neural-net-state&quot;);

NeuralNet read = NeuralNetFactory.ReadFromDirectory(&quot;../../neural-net-state&quot;);
// `read` now has the same internal state as `neuralNet`.
</code></pre>
</article>
              
                </div>
            </main>
        </div>

        
<script src="https://code.jquery.com/jquery-3.5.1.min.js" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.min.js" integrity="sha384-OgVRvuATP1z7JjHLkuOU7Xw704+h835Lr+6QL9UvYjZE3Ipu6Tp75j7Bh/kR0JKI" crossorigin="anonymous"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js"></script>
<script type="text/javascript" src="../styles/jquery.twbsPagination.js"></script>
<script type="text/javascript" src="../styles/url.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/anchor-js/anchor.min.js"></script>
<script type="text/javascript" src="../styles/docfx.js"></script>
<script type="text/javascript" src="../styles/main.js"></script>

    </body>

</html>
