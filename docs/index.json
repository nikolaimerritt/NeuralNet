{
  "api/index.html": {
    "href": "api/index.html",
    "title": "API Documentation | NeuralNet",
    "keywords": "API Documentation Full API reference for the NeuralNetLearning namespace."
  },
  "api/NeuralNetLearning.Activations.Activation.html": {
    "href": "api/NeuralNetLearning.Activations.Activation.html",
    "title": "Class Activation | NeuralNet",
    "keywords": "Class Activation Represents the activation function that is applied to a neural layer. Inheritance Object Activation IdentityActivation ReluActivation SoftmaxActivation TanhActivation Inherited Members Object.Equals(Object) Object.Equals(Object, Object) Object.GetHashCode() Object.GetType() Object.MemberwiseClone() Object.ReferenceEquals(Object, Object) Object.ToString() Namespace : NeuralNetLearning.Activations Assembly : NeuralNet.dll Syntax public abstract class Activation Methods Apply(Vector<Double>) Returns the resulting MathNet.Numerics.LinearAlgebra.Vector<T> on applying the activation function to input . Declaration public abstract Vector<double> Apply(Vector<double> input) Parameters Type Name Description MathNet.Numerics.LinearAlgebra.Vector < Double > input Returns Type Description MathNet.Numerics.LinearAlgebra.Vector < Double > Derivative(Vector<Double>) Returns the matrix of derivatives of the activation function evaluated with input . The [r, c] entry is the derivative of the r th component of the activation function, with respect to the c th component of the input. Declaration public abstract Matrix<double> Derivative(Vector<double> input) Parameters Type Name Description MathNet.Numerics.LinearAlgebra.Vector < Double > input Returns Type Description MathNet.Numerics.LinearAlgebra.Matrix < Double >"
  },
  "api/NeuralNetLearning.Activations.html": {
    "href": "api/NeuralNetLearning.Activations.html",
    "title": "Namespace NeuralNetLearning.Activations | NeuralNet",
    "keywords": "Namespace NeuralNetLearning.Activations Classes Activation Represents the activation function that is applied to a neural layer. IdentityActivation Encapsulates identity (also known as \"linear\") activation,. The input is not affected identity activation. ReluActivation Encapsulates Parametric ReLU activation. SoftmaxActivation Encapsulates softmax activation . TanhActivation Encapsulates hyperbolic tangent (tanh) activation applied to a neural layer."
  },
  "api/NeuralNetLearning.Activations.IdentityActivation.html": {
    "href": "api/NeuralNetLearning.Activations.IdentityActivation.html",
    "title": "Class IdentityActivation | NeuralNet",
    "keywords": "Class IdentityActivation Encapsulates identity (also known as \"linear\") activation,. The input is not affected identity activation. Inheritance Object Activation IdentityActivation Inherited Members Object.Equals(Object) Object.Equals(Object, Object) Object.GetHashCode() Object.GetType() Object.MemberwiseClone() Object.ReferenceEquals(Object, Object) Object.ToString() Namespace : NeuralNetLearning.Activations Assembly : NeuralNet.dll Syntax public class IdentityActivation : Activation Constructors IdentityActivation() Declaration public IdentityActivation() Methods Apply(Vector<Double>) Declaration public override Vector<double> Apply(Vector<double> input) Parameters Type Name Description MathNet.Numerics.LinearAlgebra.Vector < Double > input Returns Type Description MathNet.Numerics.LinearAlgebra.Vector < Double > Overrides Activation.Apply(Vector<Double>) Derivative(Vector<Double>) Declaration public override Matrix<double> Derivative(Vector<double> input) Parameters Type Name Description MathNet.Numerics.LinearAlgebra.Vector < Double > input Returns Type Description MathNet.Numerics.LinearAlgebra.Matrix < Double > Overrides Activation.Derivative(Vector<Double>)"
  },
  "api/NeuralNetLearning.Activations.ReluActivation.html": {
    "href": "api/NeuralNetLearning.Activations.ReluActivation.html",
    "title": "Class ReluActivation | NeuralNet",
    "keywords": "Class ReluActivation Encapsulates Parametric ReLU activation. Inheritance Object Activation ReluActivation Inherited Members Object.Equals(Object) Object.Equals(Object, Object) Object.GetHashCode() Object.GetType() Object.MemberwiseClone() Object.ReferenceEquals(Object, Object) Object.ToString() Namespace : NeuralNetLearning.Activations Assembly : NeuralNet.dll Syntax public class ReluActivation : Activation Constructors ReluActivation() Declaration public ReluActivation() ReluActivation(Double) Declaration public ReluActivation(double leak) Parameters Type Name Description Double leak Methods Apply(Vector<Double>) Declaration public override Vector<double> Apply(Vector<double> input) Parameters Type Name Description MathNet.Numerics.LinearAlgebra.Vector < Double > input Returns Type Description MathNet.Numerics.LinearAlgebra.Vector < Double > Overrides Activation.Apply(Vector<Double>) Derivative(Vector<Double>) Declaration public override Matrix<double> Derivative(Vector<double> input) Parameters Type Name Description MathNet.Numerics.LinearAlgebra.Vector < Double > input Returns Type Description MathNet.Numerics.LinearAlgebra.Matrix < Double > Overrides Activation.Derivative(Vector<Double>)"
  },
  "api/NeuralNetLearning.Activations.SoftmaxActivation.html": {
    "href": "api/NeuralNetLearning.Activations.SoftmaxActivation.html",
    "title": "Class SoftmaxActivation | NeuralNet",
    "keywords": "Class SoftmaxActivation Encapsulates softmax activation . Inheritance Object Activation SoftmaxActivation Inherited Members Object.Equals(Object) Object.Equals(Object, Object) Object.GetHashCode() Object.GetType() Object.MemberwiseClone() Object.ReferenceEquals(Object, Object) Object.ToString() Namespace : NeuralNetLearning.Activations Assembly : NeuralNet.dll Syntax public class SoftmaxActivation : Activation Constructors SoftmaxActivation() Declaration public SoftmaxActivation() Methods Apply(Vector<Double>) Declaration public override Vector<double> Apply(Vector<double> input) Parameters Type Name Description MathNet.Numerics.LinearAlgebra.Vector < Double > input Returns Type Description MathNet.Numerics.LinearAlgebra.Vector < Double > Overrides Activation.Apply(Vector<Double>) Derivative(Vector<Double>) Declaration public override Matrix<double> Derivative(Vector<double> input) Parameters Type Name Description MathNet.Numerics.LinearAlgebra.Vector < Double > input Returns Type Description MathNet.Numerics.LinearAlgebra.Matrix < Double > Overrides Activation.Derivative(Vector<Double>)"
  },
  "api/NeuralNetLearning.Activations.TanhActivation.html": {
    "href": "api/NeuralNetLearning.Activations.TanhActivation.html",
    "title": "Class TanhActivation | NeuralNet",
    "keywords": "Class TanhActivation Encapsulates hyperbolic tangent (tanh) activation applied to a neural layer. Inheritance Object Activation TanhActivation Inherited Members Object.Equals(Object) Object.Equals(Object, Object) Object.GetHashCode() Object.GetType() Object.MemberwiseClone() Object.ReferenceEquals(Object, Object) Object.ToString() Namespace : NeuralNetLearning.Activations Assembly : NeuralNet.dll Syntax public class TanhActivation : Activation Constructors TanhActivation() Declaration public TanhActivation() Methods Apply(Vector<Double>) Declaration public override Vector<double> Apply(Vector<double> input) Parameters Type Name Description MathNet.Numerics.LinearAlgebra.Vector < Double > input Returns Type Description MathNet.Numerics.LinearAlgebra.Vector < Double > Overrides Activation.Apply(Vector<Double>) Derivative(Vector<Double>) Declaration public override Matrix<double> Derivative(Vector<double> input) Parameters Type Name Description MathNet.Numerics.LinearAlgebra.Vector < Double > input Returns Type Description MathNet.Numerics.LinearAlgebra.Matrix < Double > Overrides Activation.Derivative(Vector<Double>)"
  },
  "api/NeuralNetLearning.CostFunctions.CostFunction.html": {
    "href": "api/NeuralNetLearning.CostFunctions.CostFunction.html",
    "title": "Class CostFunction | NeuralNet",
    "keywords": "Class CostFunction Represents a cost function with vector arguments. Inheritance Object CostFunction CrossEntropyCost HuberCost MSECost Inherited Members Object.Equals(Object) Object.Equals(Object, Object) Object.GetHashCode() Object.GetType() Object.MemberwiseClone() Object.ReferenceEquals(Object, Object) Object.ToString() Namespace : NeuralNetLearning.CostFunctions Assembly : NeuralNet.dll Syntax public abstract class CostFunction Methods Apply(Vector<Double>, Vector<Double>) Returns the numeric cost of the calculated vector predicted vs the target vector expected . Declaration public abstract double Apply(Vector<double> predicted, Vector<double> expected) Parameters Type Name Description MathNet.Numerics.LinearAlgebra.Vector < Double > predicted MathNet.Numerics.LinearAlgebra.Vector < Double > expected Returns Type Description Double Derivative(Vector<Double>, Vector<Double>) Returns the vector of derivatives of the cost function with respect to the calculated vector predicted . Declaration public abstract Vector<double> Derivative(Vector<double> predicted, Vector<double> expected) Parameters Type Name Description MathNet.Numerics.LinearAlgebra.Vector < Double > predicted MathNet.Numerics.LinearAlgebra.Vector < Double > expected Returns Type Description MathNet.Numerics.LinearAlgebra.Vector < Double >"
  },
  "api/NeuralNetLearning.CostFunctions.CrossEntropyCost.html": {
    "href": "api/NeuralNetLearning.CostFunctions.CrossEntropyCost.html",
    "title": "Class CrossEntropyCost | NeuralNet",
    "keywords": "Class CrossEntropyCost Encapsulates the cross-entropy cost function . Inheritance Object CostFunction CrossEntropyCost Inherited Members Object.Equals(Object) Object.Equals(Object, Object) Object.GetHashCode() Object.GetType() Object.MemberwiseClone() Object.ReferenceEquals(Object, Object) Object.ToString() Namespace : NeuralNetLearning.CostFunctions Assembly : NeuralNet.dll Syntax public class CrossEntropyCost : CostFunction Constructors CrossEntropyCost() Declaration public CrossEntropyCost() Methods Apply(Vector<Double>, Vector<Double>) Declaration public override double Apply(Vector<double> estimated, Vector<double> actual) Parameters Type Name Description MathNet.Numerics.LinearAlgebra.Vector < Double > estimated MathNet.Numerics.LinearAlgebra.Vector < Double > actual Returns Type Description Double Overrides CostFunction.Apply(Vector<Double>, Vector<Double>) Derivative(Vector<Double>, Vector<Double>) Declaration public override Vector<double> Derivative(Vector<double> estimated, Vector<double> actual) Parameters Type Name Description MathNet.Numerics.LinearAlgebra.Vector < Double > estimated MathNet.Numerics.LinearAlgebra.Vector < Double > actual Returns Type Description MathNet.Numerics.LinearAlgebra.Vector < Double > Overrides CostFunction.Derivative(Vector<Double>, Vector<Double>)"
  },
  "api/NeuralNetLearning.CostFunctions.html": {
    "href": "api/NeuralNetLearning.CostFunctions.html",
    "title": "Namespace NeuralNetLearning.CostFunctions | NeuralNet",
    "keywords": "Namespace NeuralNetLearning.CostFunctions Classes CostFunction Represents a cost function with vector arguments. CrossEntropyCost Encapsulates the cross-entropy cost function . HuberCost Encapsulates the Huber cost function . MSECost Encapsulates the mean-squared-error cost function."
  },
  "api/NeuralNetLearning.CostFunctions.HuberCost.html": {
    "href": "api/NeuralNetLearning.CostFunctions.HuberCost.html",
    "title": "Class HuberCost | NeuralNet",
    "keywords": "Class HuberCost Encapsulates the Huber cost function . Inheritance Object CostFunction HuberCost Inherited Members Object.Equals(Object) Object.Equals(Object, Object) Object.GetHashCode() Object.GetType() Object.MemberwiseClone() Object.ReferenceEquals(Object, Object) Object.ToString() Namespace : NeuralNetLearning.CostFunctions Assembly : NeuralNet.dll Syntax public class HuberCost : CostFunction Constructors HuberCost() Declaration public HuberCost() HuberCost(Double) Declaration public HuberCost(double outlierBoundary) Parameters Type Name Description Double outlierBoundary Methods Apply(Vector<Double>, Vector<Double>) Declaration public override double Apply(Vector<double> estimated, Vector<double> actual) Parameters Type Name Description MathNet.Numerics.LinearAlgebra.Vector < Double > estimated MathNet.Numerics.LinearAlgebra.Vector < Double > actual Returns Type Description Double Overrides CostFunction.Apply(Vector<Double>, Vector<Double>) Derivative(Vector<Double>, Vector<Double>) Declaration public override Vector<double> Derivative(Vector<double> estimated, Vector<double> actual) Parameters Type Name Description MathNet.Numerics.LinearAlgebra.Vector < Double > estimated MathNet.Numerics.LinearAlgebra.Vector < Double > actual Returns Type Description MathNet.Numerics.LinearAlgebra.Vector < Double > Overrides CostFunction.Derivative(Vector<Double>, Vector<Double>)"
  },
  "api/NeuralNetLearning.CostFunctions.MSECost.html": {
    "href": "api/NeuralNetLearning.CostFunctions.MSECost.html",
    "title": "Class MSECost | NeuralNet",
    "keywords": "Class MSECost Encapsulates the mean-squared-error cost function. Inheritance Object CostFunction MSECost Inherited Members Object.Equals(Object) Object.Equals(Object, Object) Object.GetHashCode() Object.GetType() Object.MemberwiseClone() Object.ReferenceEquals(Object, Object) Object.ToString() Namespace : NeuralNetLearning.CostFunctions Assembly : NeuralNet.dll Syntax public class MSECost : CostFunction Constructors MSECost() Declaration public MSECost() Methods Apply(Vector<Double>, Vector<Double>) Declaration public override double Apply(Vector<double> estimated, Vector<double> actual) Parameters Type Name Description MathNet.Numerics.LinearAlgebra.Vector < Double > estimated MathNet.Numerics.LinearAlgebra.Vector < Double > actual Returns Type Description Double Overrides CostFunction.Apply(Vector<Double>, Vector<Double>) Derivative(Vector<Double>, Vector<Double>) Declaration public override Vector<double> Derivative(Vector<double> estimated, Vector<double> actual) Parameters Type Name Description MathNet.Numerics.LinearAlgebra.Vector < Double > estimated MathNet.Numerics.LinearAlgebra.Vector < Double > actual Returns Type Description MathNet.Numerics.LinearAlgebra.Vector < Double > Overrides CostFunction.Derivative(Vector<Double>, Vector<Double>)"
  },
  "api/NeuralNetLearning.GradientDescent.AdamGradientDescender.html": {
    "href": "api/NeuralNetLearning.GradientDescent.AdamGradientDescender.html",
    "title": "Class AdamGradientDescender | NeuralNet",
    "keywords": "Class AdamGradientDescender Encapsulates the Adam gradient descent algorithm. Inheritance Object GradientDescender AdamGradientDescender Inherited Members Object.Equals(Object) Object.Equals(Object, Object) Object.GetHashCode() Object.GetType() Object.MemberwiseClone() Object.ReferenceEquals(Object, Object) Object.ToString() Namespace : NeuralNetLearning.GradientDescent Assembly : NeuralNet.dll Syntax public class AdamGradientDescender : GradientDescender Constructors AdamGradientDescender(Double, Double, Double) Constructs a new AdamGradientDescender , following the Adam gradient descent algorithm. Declaration public AdamGradientDescender(double learningRate = 0.001, double momentumDecay = 0.9, double varianceDecay = 0.999) Parameters Type Name Description Double learningRate The step size, referred to as alpha in the original paper. Double momentumDecay The initial decay rate of the momentum term, referred to as beta1 in the original paper. Double varianceDecay The initial decay rate of the variance term, referred to as beta2 in the original paper. Methods GradientDescentStep(Parameter) Declaration public override Parameter GradientDescentStep(Parameter gradient) Parameters Type Name Description Parameter gradient Returns Type Description Parameter Overrides GradientDescender.GradientDescentStep(Parameter)"
  },
  "api/NeuralNetLearning.GradientDescent.GradientDescender.html": {
    "href": "api/NeuralNetLearning.GradientDescent.GradientDescender.html",
    "title": "Class GradientDescender | NeuralNet",
    "keywords": "Class GradientDescender Encapsulates a gradient descent algorithm. Inheritance Object GradientDescender AdamGradientDescender StochasticGradientDescender Inherited Members Object.Equals(Object) Object.Equals(Object, Object) Object.GetHashCode() Object.GetType() Object.MemberwiseClone() Object.ReferenceEquals(Object, Object) Object.ToString() Namespace : NeuralNetLearning.GradientDescent Assembly : NeuralNet.dll Syntax public abstract class GradientDescender Methods GradientDescentStep(Parameter) Returns the value to add to the current Parameter in the gradient descent step. Declaration public abstract Parameter GradientDescentStep(Parameter gradient) Parameters Type Name Description Parameter gradient The cost gradient. Returns Type Description Parameter"
  },
  "api/NeuralNetLearning.GradientDescent.html": {
    "href": "api/NeuralNetLearning.GradientDescent.html",
    "title": "Namespace NeuralNetLearning.GradientDescent | NeuralNet",
    "keywords": "Namespace NeuralNetLearning.GradientDescent Classes AdamGradientDescender Encapsulates the Adam gradient descent algorithm. GradientDescender Encapsulates a gradient descent algorithm. StochasticGradientDescender Encapsulates the stochastic gradient descent algorithm."
  },
  "api/NeuralNetLearning.GradientDescent.StochasticGradientDescender.html": {
    "href": "api/NeuralNetLearning.GradientDescent.StochasticGradientDescender.html",
    "title": "Class StochasticGradientDescender | NeuralNet",
    "keywords": "Class StochasticGradientDescender Encapsulates the stochastic gradient descent algorithm. Inheritance Object GradientDescender StochasticGradientDescender Inherited Members Object.Equals(Object) Object.Equals(Object, Object) Object.GetHashCode() Object.GetType() Object.MemberwiseClone() Object.ReferenceEquals(Object, Object) Object.ToString() Namespace : NeuralNetLearning.GradientDescent Assembly : NeuralNet.dll Syntax public class StochasticGradientDescender : GradientDescender Constructors StochasticGradientDescender(Double) Declaration public StochasticGradientDescender(double learningRate = 0.001) Parameters Type Name Description Double learningRate Methods GradientDescentStep(Parameter) Declaration public override Parameter GradientDescentStep(Parameter gradient) Parameters Type Name Description Parameter gradient Returns Type Description Parameter Overrides GradientDescender.GradientDescentStep(Parameter)"
  },
  "api/NeuralNetLearning.html": {
    "href": "api/NeuralNetLearning.html",
    "title": "Namespace NeuralNetLearning | NeuralNet",
    "keywords": "Namespace NeuralNetLearning Classes NeuralNet A fully-connected neural network, with a customisable layer structure, Activation s, GradientDescender and CostFunction . NeuralNetFactory A library class that holds various techniques in initialising a NeuralNet object."
  },
  "api/NeuralNetLearning.Internal.html": {
    "href": "api/NeuralNetLearning.Internal.html",
    "title": "Namespace NeuralNetLearning.Internal | NeuralNet",
    "keywords": "Namespace NeuralNetLearning.Internal Classes MatrixFunctions A library class containing mathematical operations on MathNet.Numerics.LinearAlgebra.Matrix<T> . Parameter Encapsulates the weight MathNet.Numerics.LinearAlgebra.Matrix<T> and bias MathNet.Numerics.LinearAlgebra.Vector<T> used by NeuralNet . VectorFunctions A library class containing mathematical operaions on MathNet.Numerics.LinearAlgebra.Vector<T> ."
  },
  "api/NeuralNetLearning.Internal.MatrixFunctions.html": {
    "href": "api/NeuralNetLearning.Internal.MatrixFunctions.html",
    "title": "Class MatrixFunctions | NeuralNet",
    "keywords": "Class MatrixFunctions A library class containing mathematical operations on MathNet.Numerics.LinearAlgebra.Matrix<T> . Inheritance Object MatrixFunctions Inherited Members Object.Equals(Object) Object.Equals(Object, Object) Object.GetHashCode() Object.GetType() Object.MemberwiseClone() Object.ReferenceEquals(Object, Object) Object.ToString() Namespace : NeuralNetLearning.Internal Assembly : NeuralNet.dll Syntax public static class MatrixFunctions Methods BasisMatrices(Int32, Int32) Declaration public static Matrix<double>[] BasisMatrices(int rows, int cols) Parameters Type Name Description Int32 rows Int32 cols Returns Type Description MathNet.Numerics.LinearAlgebra.Matrix < Double >[] BasisMatrix(Int32, Int32, Int32, Int32) Declaration public static Matrix<double> BasisMatrix(int rows, int cols, int oneRow, int oneCol) Parameters Type Name Description Int32 rows Int32 cols Int32 oneRow Int32 oneCol Returns Type Description MathNet.Numerics.LinearAlgebra.Matrix < Double > GaussianOrthonormal(Int32, Int32) Declaration public static Matrix<double> GaussianOrthonormal(int rows, int cols) Parameters Type Name Description Int32 rows Int32 cols Returns Type Description MathNet.Numerics.LinearAlgebra.Matrix < Double > IsFinite(Matrix<Double>) Declaration public static bool IsFinite(Matrix<double> matrix) Parameters Type Name Description MathNet.Numerics.LinearAlgebra.Matrix < Double > matrix Returns Type Description Boolean Read(String) Declaration public static Matrix<double> Read(string filepath) Parameters Type Name Description String filepath Returns Type Description MathNet.Numerics.LinearAlgebra.Matrix < Double > StdNormal(Int32, Int32) Declaration public static Matrix<double> StdNormal(int rows, int cols) Parameters Type Name Description Int32 rows Int32 cols Returns Type Description MathNet.Numerics.LinearAlgebra.Matrix < Double > StdUniform(Int32, Int32) Declaration public static Matrix<double> StdUniform(int rows, int cols) Parameters Type Name Description Int32 rows Int32 cols Returns Type Description MathNet.Numerics.LinearAlgebra.Matrix < Double > Write(Matrix<Double>, String) Declaration public static void Write(this Matrix<double> matrix, string filepath) Parameters Type Name Description MathNet.Numerics.LinearAlgebra.Matrix < Double > matrix String filepath"
  },
  "api/NeuralNetLearning.Internal.Parameter.html": {
    "href": "api/NeuralNetLearning.Internal.Parameter.html",
    "title": "Class Parameter | NeuralNet",
    "keywords": "Class Parameter Encapsulates the weight MathNet.Numerics.LinearAlgebra.Matrix<T> and bias MathNet.Numerics.LinearAlgebra.Vector<T> used by NeuralNet . Inheritance Object Parameter Inherited Members Object.Equals(Object) Object.Equals(Object, Object) Object.GetHashCode() Object.GetType() Object.MemberwiseClone() Object.ReferenceEquals(Object, Object) Object.ToString() Namespace : NeuralNetLearning.Internal Assembly : NeuralNet.dll Syntax public class Parameter Constructors Parameter(IEnumerable<Matrix<Double>>, IEnumerable<Vector<Double>>) Creates a new Parameter object that stores the supplied weight matrices and bias vectors. Declaration public Parameter(IEnumerable<Matrix<double>> weights, IEnumerable<Vector<double>> biases) Parameters Type Name Description IEnumerable < MathNet.Numerics.LinearAlgebra.Matrix < Double >> weights The weight matrices the new Paramter object will store. A shallow copy of the IEnumerable is created. IEnumerable < MathNet.Numerics.LinearAlgebra.Vector < Double >> biases The bias vectors the new Parameter object will store. A shallow copy of the IEnumerable is created. Properties ActiveLayerCount The number of active (i.e. non-input) layers being simulated. This is equal to the number of weight matrices, which is turn is equal to the number of bias vectors. Declaration public int ActiveLayerCount { get; } Property Value Type Description Int32 EntriesCount The total number of scalar entries in the weight matrices and bias vectors. Declaration public int EntriesCount { get; } Property Value Type Description Int32 LayerSizes The size of each layer, in order of calculation. This is the size of the input, hidden, and output layers. Declaration public int[] LayerSizes { get; } Property Value Type Description Int32 [] Methods CostGradient(Vector<Double>, Vector<Double>, Activation[], CostFunction) Each entry in the returned Parameter is the derivative of the cost function with respect to the corresponding entry in the current Parameter . Declaration public Parameter CostGradient(Vector<double> input, Vector<double> expectedOutput, Activation[] activators, CostFunction cost) Parameters Type Name Description MathNet.Numerics.LinearAlgebra.Vector < Double > input The input vector. MathNet.Numerics.LinearAlgebra.Vector < Double > expectedOutput The expected output vector. Is compared to the calculated output vector in cost . Activation [] activators The activators used in calculating the layers. CostFunction cost The cost function which compares the calculated output vector to expectedOutput . Returns Type Description Parameter DeepCopy() Returns a new Parameter object with weights and biases that are deep copies of the weights and biases of the current Parameter . Changes to the current Parameter will not affect the new Parameter . Declaration public Parameter DeepCopy() Returns Type Description Parameter GetOutputVector(Vector<Double>, Activation[]) Returns the output layer as a MathNet.Numerics.LinearAlgebra.Vector<T> . Declaration public Vector<double> GetOutputVector(Vector<double> input, Activation[] activations) Parameters Type Name Description MathNet.Numerics.LinearAlgebra.Vector < Double > input The input layer as a MathNet.Numerics.LinearAlgebra.Vector<T> . Activation [] activations The Activation to apply to each layer. Note that no Activation is applied to the input layer. Returns Type Description MathNet.Numerics.LinearAlgebra.Vector < Double > A MathNet.Numerics.LinearAlgebra.Vector<T> . InPlaceAdd(Parameter) Adds the weights and biases of other directly to the weights and biases of the current Parameter . Updates the current Parameter 's weights and biases. Is more memory efficient than invoking += . Declaration public void InPlaceAdd(Parameter other) Parameters Type Name Description Parameter other The Parameter to be added component-wise. Is unaffected. Exceptions Type Condition ArithmeticException Raises if other has different layer sizes to the current Parameter . InPlaceAdd(Double) Adds scalar to every weight and bias entry of the current Parameter . Updates the current Parameter 's weights and biases. Is more memory efficient than using += . Declaration public void InPlaceAdd(double scalar) Parameters Type Name Description Double scalar Is added to every weight and bias entry. InPlaceDivide(Parameter) Divides the weights and biases in the current Parameter by the corresponding weights and biases in other . Updates the current Parameter 's weights and biases. Is more memory efficient than using /= . Declaration public void InPlaceDivide(Parameter other) Parameters Type Name Description Parameter other The Parameter that divides the current Parameter component-wise. Is unaffected by the component-wise division. Exceptions Type Condition ArithmeticException Raises if other has different layer sizes to the current Parameter . InPlaceDivide(Double) Divides every weight and bias entry of the current Parameter by scalar . Updates the current Parameter 's weights and biases. Is more memory efficient than using /= . Declaration public void InPlaceDivide(double scalar) Parameters Type Name Description Double scalar Divides every weight and bias entry. Exceptions Type Condition DivideByZeroException Raised if scalar is zero. InPlaceMultiply(Parameter) Multiplies the weights and biases in the current Parameter by the corresponding weights and biases in other . Updates the current Parameter 's weights and biases. Is more memory efficient than using *= . Declaration public void InPlaceMultiply(Parameter other) Parameters Type Name Description Parameter other The Parameter that multiplies the current Parameter component-wise. Is unaffected by the component-wise multiplication. Exceptions Type Condition ArithmeticException Raises if other has different layer sizes to the current Parameter . InPlaceMultiply(Double) Multiplies every weight and bias entry of the current Parameter by scalar . Updates the current Parameter 's weights and biases. Is more memory efficient than using *= . Declaration public void InPlaceMultiply(double scalar) Parameters Type Name Description Double scalar Multiplies every weight and bias entry. InPlacePower(Parameter) Raises each weight and bias entry in the current Parameter by the power of the corresponding weight / bias entry in in other . That is, performs component-wise exponentiation, storing the result in the current Parameter . Declaration public void InPlacePower(Parameter power) Parameters Type Name Description Parameter power Exceptions Type Condition ArithmeticException Raises if other has different layer sizes to the current Parameter . InPlacePower(Double) Raises every weight and bias entry of the current Parameter by the exponent power . Updates the current Parameter 's weights and biases. Declaration public void InPlacePower(double power) Parameters Type Name Description Double power Exponentiates every weight and bias entry. InPlaceSubtract(Parameter) Subtracts the weights and biases of other directly from the weights and biases of the current Parameter . Updates the current Parameter 's weights and biases. Is more memory efficient than using -= . Declaration public void InPlaceSubtract(Parameter other) Parameters Type Name Description Parameter other The Parameter to be added component-wise. Is unaffected by the addition. Exceptions Type Condition ArithmeticException Raises if other has different layer sizes to the current Parameter . InPlaceSubtract(Double) Subtracts scalar from every weight and bias entry of the current Parameter . Updates the current Parameter 's weights and biases. Is more memory efficient than using -= . Declaration public void InPlaceSubtract(double scalar) Parameters Type Name Description Double scalar Is subtracted from every weight and bias entry. IsFinite() Checks if each entry is finite: i.e. non-infinite and non-NaN. Declaration public bool IsFinite() Returns Type Description Boolean Pow(Double) Returns a new Parameter with each weight/bias entry raised to the exponent power . Declaration public Parameter Pow(double power) Parameters Type Name Description Double power The exponent to which every weight/bias entry is raised by. Returns Type Description Parameter A new Parameter . SetWeightsUnivariate(Activation[], IEnumerable<Vector<Double>>, Double, Int32) Adjusts the weights until the average variance of the output vectors is sufficiently close to 1. Follows the LSUV algorithm using the current weight matrices instead of random-initialised ones. Declaration public void SetWeightsUnivariate(Activation[] activators, IEnumerable<Vector<double>> inputs, double varianceTolerance, int maxIterations) Parameters Type Name Description Activation [] activators The Activation s used in calculating layers. IEnumerable < MathNet.Numerics.LinearAlgebra.Vector < Double >> inputs The input MathNet.Numerics.LinearAlgebra.Vector<T> s which the average variance of the output MathNet.Numerics.LinearAlgebra.Vector<T> is taken from. Double varianceTolerance The weights stop being adjusted once the average variance of the output vectors is between 1 - varianceTolerance and 1 + varianceTolerance . Int32 maxIterations The weights are adjusted at most maxIterations times. SquaredNorm() Returns the sum of the squares of each scalar in the weights and biases. Declaration public double SquaredNorm() Returns Type Description Double WriteToDirectory(String) Writes the weight matrices and bias vectors of the current Parameter to individual plain text files in directoryPath . The weights and biases are written in a human-readable format. Declaration public void WriteToDirectory(string directoryPath) Parameters Type Name Description String directoryPath Operators Addition(Parameter, Parameter) Declaration public static Parameter operator +(Parameter left, Parameter right) Parameters Type Name Description Parameter left Parameter right Returns Type Description Parameter Addition(Parameter, Double) Declaration public static Parameter operator +(Parameter param, double scalar) Parameters Type Name Description Parameter param Double scalar Returns Type Description Parameter Division(Parameter, Parameter) Declaration public static Parameter operator /(Parameter left, Parameter right) Parameters Type Name Description Parameter left Parameter right Returns Type Description Parameter Division(Parameter, Double) Declaration public static Parameter operator /(Parameter parameter, double scalar) Parameters Type Name Description Parameter parameter Double scalar Returns Type Description Parameter Multiply(Parameter, Parameter) Declaration public static Parameter operator *(Parameter left, Parameter right) Parameters Type Name Description Parameter left Parameter right Returns Type Description Parameter Multiply(Double, Parameter) Declaration public static Parameter operator *(double scalar, Parameter parameter) Parameters Type Name Description Double scalar Parameter parameter Returns Type Description Parameter Subtraction(Parameter, Parameter) Declaration public static Parameter operator -(Parameter left, Parameter right) Parameters Type Name Description Parameter left Parameter right Returns Type Description Parameter UnaryNegation(Parameter) Declaration public static Parameter operator -(Parameter parameter) Parameters Type Name Description Parameter parameter Returns Type Description Parameter"
  },
  "api/NeuralNetLearning.Internal.VectorFunctions.html": {
    "href": "api/NeuralNetLearning.Internal.VectorFunctions.html",
    "title": "Class VectorFunctions | NeuralNet",
    "keywords": "Class VectorFunctions A library class containing mathematical operaions on MathNet.Numerics.LinearAlgebra.Vector<T> . Inheritance Object VectorFunctions Inherited Members Object.Equals(Object) Object.Equals(Object, Object) Object.GetHashCode() Object.GetType() Object.MemberwiseClone() Object.ReferenceEquals(Object, Object) Object.ToString() Namespace : NeuralNetLearning.Internal Assembly : NeuralNet.dll Syntax public static class VectorFunctions Methods BasisVector(Int32, Int32) Declaration public static Vector<double> BasisVector(int length, int oneIdx) Parameters Type Name Description Int32 length Int32 oneIdx Returns Type Description MathNet.Numerics.LinearAlgebra.Vector < Double > BasisVectors(Int32) Declaration public static Vector<double>[] BasisVectors(int length) Parameters Type Name Description Int32 length Returns Type Description MathNet.Numerics.LinearAlgebra.Vector < Double >[] IsFinite(Vector<Double>) Declaration public static bool IsFinite(Vector<double> vector) Parameters Type Name Description MathNet.Numerics.LinearAlgebra.Vector < Double > vector Returns Type Description Boolean Read(String) Declaration public static Vector<double> Read(string filepath) Parameters Type Name Description String filepath Returns Type Description MathNet.Numerics.LinearAlgebra.Vector < Double > StdNormal(Int32) Declaration public static Vector<double> StdNormal(int dim) Parameters Type Name Description Int32 dim Returns Type Description MathNet.Numerics.LinearAlgebra.Vector < Double > StdUniform(Int32) Declaration public static Vector<double> StdUniform(int dim) Parameters Type Name Description Int32 dim Returns Type Description MathNet.Numerics.LinearAlgebra.Vector < Double > Write(Vector<Double>, String) Declaration public static void Write(this Vector<double> vector, string filepath) Parameters Type Name Description MathNet.Numerics.LinearAlgebra.Vector < Double > vector String filepath"
  },
  "api/NeuralNetLearning.LayerConfig.HiddenLayer.html": {
    "href": "api/NeuralNetLearning.LayerConfig.HiddenLayer.html",
    "title": "Class HiddenLayer | NeuralNet",
    "keywords": "Class HiddenLayer Stores the layer size and Activation used in the hidden (i.e. non-input and non-final) layer of a NeuralNet . Inheritance Object NeuralLayerConfig HiddenLayer Implements IEquatable < NeuralLayerConfig > IEquatable < HiddenLayer > Inherited Members NeuralLayerConfig.Size Object.Equals(Object) Object.Equals(Object, Object) Object.GetHashCode() Object.GetType() Object.MemberwiseClone() Object.ReferenceEquals(Object, Object) Object.ToString() Namespace : NeuralNetLearning.LayerConfig Assembly : NeuralNet.dll Syntax public class HiddenLayer : NeuralLayerConfig, IEquatable<NeuralLayerConfig>, IEquatable<HiddenLayer> Constructors HiddenLayer(Int32, Activation) Declaration public HiddenLayer(int size, Activation activation) Parameters Type Name Description Int32 size Activation activation Properties Activation Declaration public Activation Activation { get; } Property Value Type Description Activation Implements System.IEquatable<T> System.IEquatable<T>"
  },
  "api/NeuralNetLearning.LayerConfig.html": {
    "href": "api/NeuralNetLearning.LayerConfig.html",
    "title": "Namespace NeuralNetLearning.LayerConfig | NeuralNet",
    "keywords": "Namespace NeuralNetLearning.LayerConfig Classes HiddenLayer Stores the layer size and Activation used in the hidden (i.e. non-input and non-final) layer of a NeuralNet . InputLayer NeuralLayerConfig An record that abstracts InputLayer , HiddenLayer and OutputLayer . Used in specifying the layer structure to use in creating a NeuralNet via NeuralNetFactory . OutputLayer Stores the layer size and Activation used in the final layer of a NeuralNet ."
  },
  "api/NeuralNetLearning.LayerConfig.InputLayer.html": {
    "href": "api/NeuralNetLearning.LayerConfig.InputLayer.html",
    "title": "Class InputLayer | NeuralNet",
    "keywords": "Class InputLayer Inheritance Object NeuralLayerConfig InputLayer Implements IEquatable < NeuralLayerConfig > IEquatable < InputLayer > Inherited Members NeuralLayerConfig.Size Object.Equals(Object) Object.Equals(Object, Object) Object.GetHashCode() Object.GetType() Object.MemberwiseClone() Object.ReferenceEquals(Object, Object) Object.ToString() Namespace : NeuralNetLearning.LayerConfig Assembly : NeuralNet.dll Syntax public class InputLayer : NeuralLayerConfig, IEquatable<NeuralLayerConfig>, IEquatable<InputLayer> Constructors InputLayer(Int32) Declaration public InputLayer(int size) Parameters Type Name Description Int32 size Implements System.IEquatable<T> System.IEquatable<T>"
  },
  "api/NeuralNetLearning.LayerConfig.NeuralLayerConfig.html": {
    "href": "api/NeuralNetLearning.LayerConfig.NeuralLayerConfig.html",
    "title": "Class NeuralLayerConfig | NeuralNet",
    "keywords": "Class NeuralLayerConfig An record that abstracts InputLayer , HiddenLayer and OutputLayer . Used in specifying the layer structure to use in creating a NeuralNet via NeuralNetFactory . Inheritance Object NeuralLayerConfig HiddenLayer InputLayer OutputLayer Implements IEquatable < NeuralLayerConfig > Inherited Members Object.Equals(Object) Object.Equals(Object, Object) Object.GetHashCode() Object.GetType() Object.MemberwiseClone() Object.ReferenceEquals(Object, Object) Object.ToString() Namespace : NeuralNetLearning.LayerConfig Assembly : NeuralNet.dll Syntax public abstract class NeuralLayerConfig : IEquatable<NeuralLayerConfig> Properties Size The amount of nodes in the layer. Declaration public int Size { get; protected set; } Property Value Type Description Int32 Implements System.IEquatable<T>"
  },
  "api/NeuralNetLearning.LayerConfig.OutputLayer.html": {
    "href": "api/NeuralNetLearning.LayerConfig.OutputLayer.html",
    "title": "Class OutputLayer | NeuralNet",
    "keywords": "Class OutputLayer Stores the layer size and Activation used in the final layer of a NeuralNet . Inheritance Object NeuralLayerConfig OutputLayer Implements IEquatable < NeuralLayerConfig > IEquatable < OutputLayer > Inherited Members NeuralLayerConfig.Size Object.Equals(Object) Object.Equals(Object, Object) Object.GetHashCode() Object.GetType() Object.MemberwiseClone() Object.ReferenceEquals(Object, Object) Object.ToString() Namespace : NeuralNetLearning.LayerConfig Assembly : NeuralNet.dll Syntax public class OutputLayer : NeuralLayerConfig, IEquatable<NeuralLayerConfig>, IEquatable<OutputLayer> Constructors OutputLayer(Int32) Creates a new OutputLayer with Activation Declaration public OutputLayer(int size) Parameters Type Name Description Int32 size OutputLayer(Int32, Activation) Declaration public OutputLayer(int size, Activation activation) Parameters Type Name Description Int32 size Activation activation Properties Activation The applied to the output layer. Declaration public Activation Activation { get; } Property Value Type Description Activation Implements System.IEquatable<T> System.IEquatable<T>"
  },
  "api/NeuralNetLearning.Maths.Activations.Activation.html": {
    "href": "api/NeuralNetLearning.Maths.Activations.Activation.html",
    "title": "Class Activation | NeuralNet",
    "keywords": "Class Activation Represents the activation function that is applied to a neural layer. Inheritance Object Activation IdentityActivation ReluActivation SoftmaxActivation TanhActivation Inherited Members Object.Equals(Object) Object.Equals(Object, Object) Object.GetHashCode() Object.GetType() Object.MemberwiseClone() Object.ReferenceEquals(Object, Object) Object.ToString() Namespace : NeuralNetLearning.Maths.Activations Assembly : NeuralNet.dll Syntax public abstract class Activation Methods Apply(Vector<Double>) Returns the resulting MathNet.Numerics.LinearAlgebra.Vector<T> on applying the activation function to input . Declaration public abstract Vector<double> Apply(Vector<double> input) Parameters Type Name Description MathNet.Numerics.LinearAlgebra.Vector < Double > input Returns Type Description MathNet.Numerics.LinearAlgebra.Vector < Double > Derivative(Vector<Double>) Returns the matrix of derivatives of the activation function evaluated with input . The [r, c] entry is the derivative of the r th component of the activation function, with respect to the c th component of the input. Declaration public abstract Matrix<double> Derivative(Vector<double> input) Parameters Type Name Description MathNet.Numerics.LinearAlgebra.Vector < Double > input Returns Type Description MathNet.Numerics.LinearAlgebra.Matrix < Double >"
  },
  "api/NeuralNetLearning.Maths.Activations.html": {
    "href": "api/NeuralNetLearning.Maths.Activations.html",
    "title": "Namespace NeuralNetLearning.Maths.Activations | NeuralNet",
    "keywords": "Namespace NeuralNetLearning.Maths.Activations Classes Activation Represents the activation function that is applied to a neural layer. IdentityActivation ReluActivation SoftmaxActivation TanhActivation"
  },
  "api/NeuralNetLearning.Maths.Activations.IdentityActivation.html": {
    "href": "api/NeuralNetLearning.Maths.Activations.IdentityActivation.html",
    "title": "Class IdentityActivation | NeuralNet",
    "keywords": "Class IdentityActivation Inheritance Object Activation IdentityActivation Inherited Members Object.Equals(Object) Object.Equals(Object, Object) Object.GetHashCode() Object.GetType() Object.MemberwiseClone() Object.ReferenceEquals(Object, Object) Object.ToString() Namespace : NeuralNetLearning.Maths.Activations Assembly : NeuralNet.dll Syntax public class IdentityActivation : Activation Constructors IdentityActivation() Declaration public IdentityActivation() Methods Apply(Vector<Double>) Declaration public override Vector<double> Apply(Vector<double> input) Parameters Type Name Description MathNet.Numerics.LinearAlgebra.Vector < Double > input Returns Type Description MathNet.Numerics.LinearAlgebra.Vector < Double > Overrides Activation.Apply(Vector<Double>) Derivative(Vector<Double>) Declaration public override Matrix<double> Derivative(Vector<double> input) Parameters Type Name Description MathNet.Numerics.LinearAlgebra.Vector < Double > input Returns Type Description MathNet.Numerics.LinearAlgebra.Matrix < Double > Overrides Activation.Derivative(Vector<Double>)"
  },
  "api/NeuralNetLearning.Maths.Activations.ReluActivation.html": {
    "href": "api/NeuralNetLearning.Maths.Activations.ReluActivation.html",
    "title": "Class ReluActivation | NeuralNet",
    "keywords": "Class ReluActivation Inheritance Object Activation ReluActivation Inherited Members Object.Equals(Object) Object.Equals(Object, Object) Object.GetHashCode() Object.GetType() Object.MemberwiseClone() Object.ReferenceEquals(Object, Object) Object.ToString() Namespace : NeuralNetLearning.Maths.Activations Assembly : NeuralNet.dll Syntax public class ReluActivation : Activation Constructors ReluActivation() Declaration public ReluActivation() ReluActivation(Double) Declaration public ReluActivation(double leak) Parameters Type Name Description Double leak Methods Apply(Vector<Double>) Declaration public override Vector<double> Apply(Vector<double> input) Parameters Type Name Description MathNet.Numerics.LinearAlgebra.Vector < Double > input Returns Type Description MathNet.Numerics.LinearAlgebra.Vector < Double > Overrides Activation.Apply(Vector<Double>) Derivative(Vector<Double>) Declaration public override Matrix<double> Derivative(Vector<double> input) Parameters Type Name Description MathNet.Numerics.LinearAlgebra.Vector < Double > input Returns Type Description MathNet.Numerics.LinearAlgebra.Matrix < Double > Overrides Activation.Derivative(Vector<Double>)"
  },
  "api/NeuralNetLearning.Maths.Activations.SoftmaxActivation.html": {
    "href": "api/NeuralNetLearning.Maths.Activations.SoftmaxActivation.html",
    "title": "Class SoftmaxActivation | NeuralNet",
    "keywords": "Class SoftmaxActivation Inheritance Object Activation SoftmaxActivation Inherited Members Object.Equals(Object) Object.Equals(Object, Object) Object.GetHashCode() Object.GetType() Object.MemberwiseClone() Object.ReferenceEquals(Object, Object) Object.ToString() Namespace : NeuralNetLearning.Maths.Activations Assembly : NeuralNet.dll Syntax public class SoftmaxActivation : Activation Constructors SoftmaxActivation() Declaration public SoftmaxActivation() Methods Apply(Vector<Double>) Declaration public override Vector<double> Apply(Vector<double> input) Parameters Type Name Description MathNet.Numerics.LinearAlgebra.Vector < Double > input Returns Type Description MathNet.Numerics.LinearAlgebra.Vector < Double > Overrides Activation.Apply(Vector<Double>) Derivative(Vector<Double>) Declaration public override Matrix<double> Derivative(Vector<double> input) Parameters Type Name Description MathNet.Numerics.LinearAlgebra.Vector < Double > input Returns Type Description MathNet.Numerics.LinearAlgebra.Matrix < Double > Overrides Activation.Derivative(Vector<Double>)"
  },
  "api/NeuralNetLearning.Maths.Activations.TanhActivation.html": {
    "href": "api/NeuralNetLearning.Maths.Activations.TanhActivation.html",
    "title": "Class TanhActivation | NeuralNet",
    "keywords": "Class TanhActivation Inheritance Object Activation TanhActivation Inherited Members Object.Equals(Object) Object.Equals(Object, Object) Object.GetHashCode() Object.GetType() Object.MemberwiseClone() Object.ReferenceEquals(Object, Object) Object.ToString() Namespace : NeuralNetLearning.Maths.Activations Assembly : NeuralNet.dll Syntax public class TanhActivation : Activation Constructors TanhActivation() Declaration public TanhActivation() Methods Apply(Vector<Double>) Declaration public override Vector<double> Apply(Vector<double> input) Parameters Type Name Description MathNet.Numerics.LinearAlgebra.Vector < Double > input Returns Type Description MathNet.Numerics.LinearAlgebra.Vector < Double > Overrides Activation.Apply(Vector<Double>) Derivative(Vector<Double>) Declaration public override Matrix<double> Derivative(Vector<double> input) Parameters Type Name Description MathNet.Numerics.LinearAlgebra.Vector < Double > input Returns Type Description MathNet.Numerics.LinearAlgebra.Matrix < Double > Overrides Activation.Derivative(Vector<Double>)"
  },
  "api/NeuralNetLearning.Maths.CostFunctions.CostFunction.html": {
    "href": "api/NeuralNetLearning.Maths.CostFunctions.CostFunction.html",
    "title": "Class CostFunction | NeuralNet",
    "keywords": "Class CostFunction Represents a cost function with vector arguments. Inheritance Object CostFunction CrossEntropyCost HuberCost MSECost Inherited Members Object.Equals(Object) Object.Equals(Object, Object) Object.GetHashCode() Object.GetType() Object.MemberwiseClone() Object.ReferenceEquals(Object, Object) Object.ToString() Namespace : NeuralNetLearning.Maths.CostFunctions Assembly : NeuralNet.dll Syntax public abstract class CostFunction Methods Apply(Vector<Double>, Vector<Double>) Returns the numeric cost of the calculated vector predicted vs the target vector expected . Declaration public abstract double Apply(Vector<double> predicted, Vector<double> expected) Parameters Type Name Description MathNet.Numerics.LinearAlgebra.Vector < Double > predicted MathNet.Numerics.LinearAlgebra.Vector < Double > expected Returns Type Description Double Derivative(Vector<Double>, Vector<Double>) Returns the vector of derivatives of the cost function with respect to the calculated vector predicted . Declaration public abstract Vector<double> Derivative(Vector<double> predicted, Vector<double> expected) Parameters Type Name Description MathNet.Numerics.LinearAlgebra.Vector < Double > predicted MathNet.Numerics.LinearAlgebra.Vector < Double > expected Returns Type Description MathNet.Numerics.LinearAlgebra.Vector < Double >"
  },
  "api/NeuralNetLearning.Maths.CostFunctions.CrossEntropyCost.html": {
    "href": "api/NeuralNetLearning.Maths.CostFunctions.CrossEntropyCost.html",
    "title": "Class CrossEntropyCost | NeuralNet",
    "keywords": "Class CrossEntropyCost Inheritance Object CostFunction CrossEntropyCost Inherited Members Object.Equals(Object) Object.Equals(Object, Object) Object.GetHashCode() Object.GetType() Object.MemberwiseClone() Object.ReferenceEquals(Object, Object) Object.ToString() Namespace : NeuralNetLearning.Maths.CostFunctions Assembly : NeuralNet.dll Syntax public class CrossEntropyCost : CostFunction Constructors CrossEntropyCost() Declaration public CrossEntropyCost() Methods Apply(Vector<Double>, Vector<Double>) Declaration public override double Apply(Vector<double> estimated, Vector<double> actual) Parameters Type Name Description MathNet.Numerics.LinearAlgebra.Vector < Double > estimated MathNet.Numerics.LinearAlgebra.Vector < Double > actual Returns Type Description Double Overrides CostFunction.Apply(Vector<Double>, Vector<Double>) Derivative(Vector<Double>, Vector<Double>) Declaration public override Vector<double> Derivative(Vector<double> estimated, Vector<double> actual) Parameters Type Name Description MathNet.Numerics.LinearAlgebra.Vector < Double > estimated MathNet.Numerics.LinearAlgebra.Vector < Double > actual Returns Type Description MathNet.Numerics.LinearAlgebra.Vector < Double > Overrides CostFunction.Derivative(Vector<Double>, Vector<Double>)"
  },
  "api/NeuralNetLearning.Maths.CostFunctions.html": {
    "href": "api/NeuralNetLearning.Maths.CostFunctions.html",
    "title": "Namespace NeuralNetLearning.Maths.CostFunctions | NeuralNet",
    "keywords": "Namespace NeuralNetLearning.Maths.CostFunctions Classes CostFunction Represents a cost function with vector arguments. CrossEntropyCost HuberCost MSECost"
  },
  "api/NeuralNetLearning.Maths.CostFunctions.HuberCost.html": {
    "href": "api/NeuralNetLearning.Maths.CostFunctions.HuberCost.html",
    "title": "Class HuberCost | NeuralNet",
    "keywords": "Class HuberCost Inheritance Object CostFunction HuberCost Inherited Members Object.Equals(Object) Object.Equals(Object, Object) Object.GetHashCode() Object.GetType() Object.MemberwiseClone() Object.ReferenceEquals(Object, Object) Object.ToString() Namespace : NeuralNetLearning.Maths.CostFunctions Assembly : NeuralNet.dll Syntax public class HuberCost : CostFunction Constructors HuberCost() Declaration public HuberCost() HuberCost(Double) Declaration public HuberCost(double outlierBoundary) Parameters Type Name Description Double outlierBoundary Methods Apply(Vector<Double>, Vector<Double>) Declaration public override double Apply(Vector<double> estimated, Vector<double> actual) Parameters Type Name Description MathNet.Numerics.LinearAlgebra.Vector < Double > estimated MathNet.Numerics.LinearAlgebra.Vector < Double > actual Returns Type Description Double Overrides CostFunction.Apply(Vector<Double>, Vector<Double>) Derivative(Vector<Double>, Vector<Double>) Declaration public override Vector<double> Derivative(Vector<double> estimated, Vector<double> actual) Parameters Type Name Description MathNet.Numerics.LinearAlgebra.Vector < Double > estimated MathNet.Numerics.LinearAlgebra.Vector < Double > actual Returns Type Description MathNet.Numerics.LinearAlgebra.Vector < Double > Overrides CostFunction.Derivative(Vector<Double>, Vector<Double>)"
  },
  "api/NeuralNetLearning.Maths.CostFunctions.MSECost.html": {
    "href": "api/NeuralNetLearning.Maths.CostFunctions.MSECost.html",
    "title": "Class MSECost | NeuralNet",
    "keywords": "Class MSECost Inheritance Object CostFunction MSECost Inherited Members Object.Equals(Object) Object.Equals(Object, Object) Object.GetHashCode() Object.GetType() Object.MemberwiseClone() Object.ReferenceEquals(Object, Object) Object.ToString() Namespace : NeuralNetLearning.Maths.CostFunctions Assembly : NeuralNet.dll Syntax public class MSECost : CostFunction Constructors MSECost() Declaration public MSECost() Methods Apply(Vector<Double>, Vector<Double>) Declaration public override double Apply(Vector<double> estimated, Vector<double> actual) Parameters Type Name Description MathNet.Numerics.LinearAlgebra.Vector < Double > estimated MathNet.Numerics.LinearAlgebra.Vector < Double > actual Returns Type Description Double Overrides CostFunction.Apply(Vector<Double>, Vector<Double>) Derivative(Vector<Double>, Vector<Double>) Declaration public override Vector<double> Derivative(Vector<double> estimated, Vector<double> actual) Parameters Type Name Description MathNet.Numerics.LinearAlgebra.Vector < Double > estimated MathNet.Numerics.LinearAlgebra.Vector < Double > actual Returns Type Description MathNet.Numerics.LinearAlgebra.Vector < Double > Overrides CostFunction.Derivative(Vector<Double>, Vector<Double>)"
  },
  "api/NeuralNetLearning.Maths.GradientDescent.AdamGradientDescender.html": {
    "href": "api/NeuralNetLearning.Maths.GradientDescent.AdamGradientDescender.html",
    "title": "Class AdamGradientDescender | NeuralNet",
    "keywords": "Class AdamGradientDescender Inheritance Object GradientDescender AdamGradientDescender Inherited Members Object.Equals(Object) Object.Equals(Object, Object) Object.GetHashCode() Object.GetType() Object.MemberwiseClone() Object.ReferenceEquals(Object, Object) Object.ToString() Namespace : NeuralNetLearning.Maths.GradientDescent Assembly : NeuralNet.dll Syntax public class AdamGradientDescender : GradientDescender Constructors AdamGradientDescender() Declaration public AdamGradientDescender() AdamGradientDescender(Double, Double, Double) Declaration public AdamGradientDescender(double learningRate = 0.001, double momentumDecay = 0.9, double varianceDecay = 0.999) Parameters Type Name Description Double learningRate Double momentumDecay Double varianceDecay Methods GradientDescentStep(Parameter) Declaration public override Parameter GradientDescentStep(Parameter gradient) Parameters Type Name Description Parameter gradient Returns Type Description Parameter Overrides GradientDescender.GradientDescentStep(Parameter)"
  },
  "api/NeuralNetLearning.Maths.GradientDescent.GradientDescender.html": {
    "href": "api/NeuralNetLearning.Maths.GradientDescent.GradientDescender.html",
    "title": "Class GradientDescender | NeuralNet",
    "keywords": "Class GradientDescender Inheritance Object GradientDescender AdamGradientDescender StochasticGradientDescender Inherited Members Object.Equals(Object) Object.Equals(Object, Object) Object.GetHashCode() Object.GetType() Object.MemberwiseClone() Object.ReferenceEquals(Object, Object) Object.ToString() Namespace : NeuralNetLearning.Maths.GradientDescent Assembly : NeuralNet.dll Syntax public abstract class GradientDescender Methods GradientDescentStep(Parameter) The filename to which the hyper-parameters of type Double are written. Declaration public abstract Parameter GradientDescentStep(Parameter gradient) Parameters Type Name Description Parameter gradient The cost gradient Returns Type Description Parameter"
  },
  "api/NeuralNetLearning.Maths.GradientDescent.html": {
    "href": "api/NeuralNetLearning.Maths.GradientDescent.html",
    "title": "Namespace NeuralNetLearning.Maths.GradientDescent | NeuralNet",
    "keywords": "Namespace NeuralNetLearning.Maths.GradientDescent Classes AdamGradientDescender GradientDescender StochasticGradientDescender"
  },
  "api/NeuralNetLearning.Maths.GradientDescent.StochasticGradientDescender.html": {
    "href": "api/NeuralNetLearning.Maths.GradientDescent.StochasticGradientDescender.html",
    "title": "Class StochasticGradientDescender | NeuralNet",
    "keywords": "Class StochasticGradientDescender Inheritance Object GradientDescender StochasticGradientDescender Inherited Members Object.Equals(Object) Object.Equals(Object, Object) Object.GetHashCode() Object.GetType() Object.MemberwiseClone() Object.ReferenceEquals(Object, Object) Object.ToString() Namespace : NeuralNetLearning.Maths.GradientDescent Assembly : NeuralNet.dll Syntax public class StochasticGradientDescender : GradientDescender Constructors StochasticGradientDescender() Declaration public StochasticGradientDescender() StochasticGradientDescender(Double) Declaration public StochasticGradientDescender(double learningRate = 0.001) Parameters Type Name Description Double learningRate Methods GradientDescentStep(Parameter) Declaration public override Parameter GradientDescentStep(Parameter gradient) Parameters Type Name Description Parameter gradient Returns Type Description Parameter Overrides GradientDescender.GradientDescentStep(Parameter) HyperParametersToLines() Declaration public string[] HyperParametersToLines() Returns Type Description String []"
  },
  "api/NeuralNetLearning.Maths.html": {
    "href": "api/NeuralNetLearning.Maths.html",
    "title": "Namespace NeuralNetLearning.Maths | NeuralNet",
    "keywords": "Namespace NeuralNetLearning.Maths Classes MatrixFunctions Parameter VectorFunctions"
  },
  "api/NeuralNetLearning.Maths.MatrixFunctions.html": {
    "href": "api/NeuralNetLearning.Maths.MatrixFunctions.html",
    "title": "Class MatrixFunctions | NeuralNet",
    "keywords": "Class MatrixFunctions Inheritance Object MatrixFunctions Inherited Members Object.Equals(Object) Object.Equals(Object, Object) Object.GetHashCode() Object.GetType() Object.MemberwiseClone() Object.ReferenceEquals(Object, Object) Object.ToString() Namespace : NeuralNetLearning.Maths Assembly : NeuralNet.dll Syntax public static class MatrixFunctions Methods BasisMatrices(Int32, Int32) Declaration public static Matrix<double>[] BasisMatrices(int rows, int cols) Parameters Type Name Description Int32 rows Int32 cols Returns Type Description MathNet.Numerics.LinearAlgebra.Matrix < Double >[] BasisMatrix(Int32, Int32, Int32, Int32) Declaration public static Matrix<double> BasisMatrix(int rows, int cols, int oneRow, int oneCol) Parameters Type Name Description Int32 rows Int32 cols Int32 oneRow Int32 oneCol Returns Type Description MathNet.Numerics.LinearAlgebra.Matrix < Double > GaussianOrthonormal(Int32, Int32) Declaration public static Matrix<double> GaussianOrthonormal(int rows, int cols) Parameters Type Name Description Int32 rows Int32 cols Returns Type Description MathNet.Numerics.LinearAlgebra.Matrix < Double > IsFinite(Matrix<Double>) Declaration public static bool IsFinite(Matrix<double> matrix) Parameters Type Name Description MathNet.Numerics.LinearAlgebra.Matrix < Double > matrix Returns Type Description Boolean Read(String) Declaration public static Matrix<double> Read(string filepath) Parameters Type Name Description String filepath Returns Type Description MathNet.Numerics.LinearAlgebra.Matrix < Double > StdNormal(Int32, Int32) Declaration public static Matrix<double> StdNormal(int rows, int cols) Parameters Type Name Description Int32 rows Int32 cols Returns Type Description MathNet.Numerics.LinearAlgebra.Matrix < Double > StdUniform(Int32, Int32) Declaration public static Matrix<double> StdUniform(int rows, int cols) Parameters Type Name Description Int32 rows Int32 cols Returns Type Description MathNet.Numerics.LinearAlgebra.Matrix < Double > Write(Matrix<Double>, String) Declaration public static void Write(this Matrix<double> matrix, string filepath) Parameters Type Name Description MathNet.Numerics.LinearAlgebra.Matrix < Double > matrix String filepath"
  },
  "api/NeuralNetLearning.Maths.Parameter.html": {
    "href": "api/NeuralNetLearning.Maths.Parameter.html",
    "title": "Class Parameter | NeuralNet",
    "keywords": "Class Parameter Inheritance Object Parameter Inherited Members Object.Equals(Object) Object.Equals(Object, Object) Object.GetHashCode() Object.GetType() Object.MemberwiseClone() Object.ReferenceEquals(Object, Object) Object.ToString() Namespace : NeuralNetLearning.Maths Assembly : NeuralNet.dll Syntax public class Parameter Constructors Parameter(IEnumerable<Matrix<Double>>, IEnumerable<Vector<Double>>) Creates a new Parameter object that stores the supplied weight matrices and bias vectors. Declaration public Parameter(IEnumerable<Matrix<double>> weights, IEnumerable<Vector<double>> biases) Parameters Type Name Description IEnumerable < MathNet.Numerics.LinearAlgebra.Matrix < Double >> weights The weight matrices the new Paramter object will store. A shallow copy of the IEnumerable is created. IEnumerable < MathNet.Numerics.LinearAlgebra.Vector < Double >> biases The bias vectors the new Parameter object will store. A shallow copy of the IEnumerable is created. Properties ActiveLayerCount The number of active (i.e. non-input) layers being simulated. This is equal to the number of weight matrices, which is turn is equal to the number of bias vectors. Declaration public int ActiveLayerCount { get; } Property Value Type Description Int32 EntriesCount The total number of scalar entries in the weight matrices and bias vectors. Declaration public int EntriesCount { get; } Property Value Type Description Int32 LayerSizes The size of each layer, in order of calculation. This is the size of the input, hidden, and output layers. Declaration public int[] LayerSizes { get; } Property Value Type Description Int32 [] Methods CostGradient(Vector<Double>, Vector<Double>, Activation[], CostFunction) Each entry in the returned Parameter is the derivative of the cost function with respect to the corresponding entry in the current Parameter . Declaration public Parameter CostGradient(Vector<double> input, Vector<double> desiredOutput, Activation[] activators, CostFunction cost) Parameters Type Name Description MathNet.Numerics.LinearAlgebra.Vector < Double > input The input vector. MathNet.Numerics.LinearAlgebra.Vector < Double > desiredOutput The expected output vector. Is compared to the calculated output vector in cost . Activation [] activators The activators used in calculating the layers. CostFunction cost The cost function which compares the calculated output vector to desiredOutput . Returns Type Description Parameter DeepCopy() Returns a new Parameter object with weights and biases that are deep copies of the weights and biases of the current Parameter . Changes to the current Parameter will not affect the new Parameter . Declaration public Parameter DeepCopy() Returns Type Description Parameter GetOutputVector(Vector<Double>, Activation[]) Declaration public Vector<double> GetOutputVector(Vector<double> input, Activation[] activators) Parameters Type Name Description MathNet.Numerics.LinearAlgebra.Vector < Double > input Activation [] activators Returns Type Description MathNet.Numerics.LinearAlgebra.Vector < Double > InPlaceAdd(Parameter) Adds the weights and biases of other directly to the weights and biases of the current Parameter . Updates the current Parameter 's weights and biases. Is more memory efficient than invoking += . Declaration public void InPlaceAdd(Parameter other) Parameters Type Name Description Parameter other The Parameter to be added component-wise. Is unaffected. Exceptions Type Condition ArithmeticException Raises if other has different layer sizes to the current Parameter . InPlaceAdd(Double) Adds scalar to every weight and bias entry of the current Parameter . Updates the current Parameter 's weights and biases. Is more memory efficient than using += . Declaration public void InPlaceAdd(double scalar) Parameters Type Name Description Double scalar Is added to every weight and bias entry. InPlaceDivide(Parameter) Divides the weights and biases in the current Parameter by the corresponding weights and biases in other . Updates the current Parameter 's weights and biases. Is more memory efficient than using /= . Declaration public void InPlaceDivide(Parameter other) Parameters Type Name Description Parameter other The Parameter that divides the current Parameter component-wise. Is unaffected by the component-wise division. Exceptions Type Condition ArithmeticException Raises if other has different layer sizes to the current Parameter . InPlaceDivide(Double) Divides every weight and bias entry of the current Parameter by scalar . Updates the current Parameter 's weights and biases. Is more memory efficient than using /= . Declaration public void InPlaceDivide(double scalar) Parameters Type Name Description Double scalar Divides every weight and bias entry. Exceptions Type Condition DivideByZeroException Raised if scalar is zero. InPlaceMultiply(Parameter) Multiplies the weights and biases in the current Parameter by the corresponding weights and biases in other . Updates the current Parameter 's weights and biases. Is more memory efficient than using *= . Declaration public void InPlaceMultiply(Parameter other) Parameters Type Name Description Parameter other The Parameter that multiplies the current Parameter component-wise. Is unaffected by the component-wise multiplication. Exceptions Type Condition ArithmeticException Raises if other has different layer sizes to the current Parameter . InPlaceMultiply(Double) Multiplies every weight and bias entry of the current Parameter by scalar . Updates the current Parameter 's weights and biases. Is more memory efficient than using *= . Declaration public void InPlaceMultiply(double scalar) Parameters Type Name Description Double scalar Multiplies every weight and bias entry. InPlacePower(Parameter) Raises each weight and bias entry in the current Parameter by the power of the corresponding weight / bias entry in in other . That is, performs component-wise exponentiation, storing the result in the current Parameter . Declaration public void InPlacePower(Parameter power) Parameters Type Name Description Parameter power Exceptions Type Condition ArithmeticException Raises if other has different layer sizes to the current Parameter . InPlacePower(Double) Raises every weight and bias entry of the current Parameter by the exponent power . Updates the current Parameter 's weights and biases. Declaration public void InPlacePower(double power) Parameters Type Name Description Double power Exponentiates every weight and bias entry. InPlaceSubtract(Parameter) Subtracts the weights and biases of other directly from the weights and biases of the current Parameter . Updates the current Parameter 's weights and biases. Is more memory efficient than using -= . Declaration public void InPlaceSubtract(Parameter other) Parameters Type Name Description Parameter other The Parameter to be added component-wise. Is unaffected by the addition. Exceptions Type Condition ArithmeticException Raises if other has different layer sizes to the current Parameter . InPlaceSubtract(Double) Subtracts scalar from every weight and bias entry of the current Parameter . Updates the current Parameter 's weights and biases. Is more memory efficient than using -= . Declaration public void InPlaceSubtract(double scalar) Parameters Type Name Description Double scalar Is subtracted from every weight and bias entry. IsFinite() Checks if each entry is finite: i.e. non-infinite and non-NaN. Declaration public bool IsFinite() Returns Type Description Boolean Pow(Double) Declaration public Parameter Pow(double power) Parameters Type Name Description Double power Returns Type Description Parameter SetWeightsUnivariate(Activation[], IEnumerable<Vector<Double>>, Double, Int32) Adjusts the weights until the average variance of the output vectors is sufficiently close to 1. Follows the LSUV algorithm using the current weight matrices instead of random-initialised ones. Declaration public void SetWeightsUnivariate(Activation[] activators, IEnumerable<Vector<double>> inputs, double varianceTolerance, int maxIterations) Parameters Type Name Description Activation [] activators The Activation s used in calculating layers. IEnumerable < MathNet.Numerics.LinearAlgebra.Vector < Double >> inputs The input MathNet.Numerics.LinearAlgebra.Vector<T> s which the average variance of the output MathNet.Numerics.LinearAlgebra.Vector<T> is taken from. Double varianceTolerance The weights stop being adjusted once the average variance of the output vectors is between 1 - varianceTolerance and 1 + varianceTolerance . Int32 maxIterations The weights are adjusted at most maxIterations times. SquaredNorm() Returns the sum of the squares of each scalar in the weights and biases. Declaration public double SquaredNorm() Returns Type Description Double WriteToDirectory(String) Writes the weight matrices and bias vectors of the current Parameter to individual plain text files in directoryPath . The weights and biases are written in a human-readable format. Declaration public void WriteToDirectory(string directoryPath) Parameters Type Name Description String directoryPath Operators Addition(Parameter, Parameter) Declaration public static Parameter operator +(Parameter left, Parameter right) Parameters Type Name Description Parameter left Parameter right Returns Type Description Parameter Addition(Parameter, Double) Declaration public static Parameter operator +(Parameter param, double scalar) Parameters Type Name Description Parameter param Double scalar Returns Type Description Parameter Division(Parameter, Parameter) Declaration public static Parameter operator /(Parameter left, Parameter right) Parameters Type Name Description Parameter left Parameter right Returns Type Description Parameter Division(Parameter, Double) Declaration public static Parameter operator /(Parameter parameter, double scalar) Parameters Type Name Description Parameter parameter Double scalar Returns Type Description Parameter Multiply(Parameter, Parameter) Declaration public static Parameter operator *(Parameter left, Parameter right) Parameters Type Name Description Parameter left Parameter right Returns Type Description Parameter Multiply(Double, Parameter) Declaration public static Parameter operator *(double scalar, Parameter parameter) Parameters Type Name Description Double scalar Parameter parameter Returns Type Description Parameter Subtraction(Parameter, Parameter) Declaration public static Parameter operator -(Parameter left, Parameter right) Parameters Type Name Description Parameter left Parameter right Returns Type Description Parameter UnaryNegation(Parameter) Declaration public static Parameter operator -(Parameter parameter) Parameters Type Name Description Parameter parameter Returns Type Description Parameter"
  },
  "api/NeuralNetLearning.Maths.ParameterFactory.html": {
    "href": "api/NeuralNetLearning.Maths.ParameterFactory.html",
    "title": "Class ParameterFactory | NeuralNet",
    "keywords": "Class ParameterFactory Inheritance Object ParameterFactory Inherited Members Object.Equals(Object) Object.Equals(Object, Object) Object.GetHashCode() Object.GetType() Object.MemberwiseClone() Object.ReferenceEquals(Object, Object) Object.ToString() Namespace : NeuralNetLearning.Maths Assembly : NeuralNet.dll Syntax public static class ParameterFactory Methods GaussianOrthonormal(Int32[]) Returns a Parameter object with zero biases, and orthonormal weights constructed from a Gaussian matrix. Declaration public static Parameter GaussianOrthonormal(params int[] layerSizes) Parameters Type Name Description Int32 [] layerSizes The layer sizes of the Parameter object Returns Type Description Parameter KaimingInit(Int32[]) Returns a Parameter with random weights and biases optimised for gradient descent using Relu activators. Uses Kaiming-He initialisation. Declaration public static Parameter KaimingInit(params int[] layerSizes) Parameters Type Name Description Int32 [] layerSizes The layer sizes of the Parameter object. Returns Type Description Parameter LSUVInit(Int32[], Activation[], IEnumerable<Vector<Double>>, Double, Int32) Returns a Parameter with random weights and biases optimised for learning the training data set with input data supplied in inputs . Uses LSUV initialisation . Declaration public static Parameter LSUVInit(int[] layerSizes, Activation[] activators, IEnumerable<Vector<double>> inputs, double varianceTolerance = 0.05, int maxIterations = 5) Parameters Type Name Description Int32 [] layerSizes The layer sizes of the Parameter object. Activation [] activators The activators which the Parameter will be optimised to use. IEnumerable < MathNet.Numerics.LinearAlgebra.Vector < Double >> inputs The inputs of the training data set which the Parameter will be optimised to learn. Double varianceTolerance The weights will stop being adjusted when their average variance is at most an error of varianceTolerance away from 1 Int32 maxIterations The weights will be adjusted at most maxIterations times. Returns Type Description Parameter ReadFromDirectory(String) Reads the Parameter that has been written to directoryPath using WriteToDirectory(String) . The returned Parameter has equivalent weight and bias values compared to the written Parameter . Declaration public static Parameter ReadFromDirectory(string directoryPath) Parameters Type Name Description String directoryPath The (relative or absolute) path to the directory storing the Parameter. Returns Type Description Parameter XavierInit(Int32[]) Returns a Parameter with random weights and biases optimised for gradient descent using TanhSigmoid activators. Uses Xavier initialisation. Declaration public static Parameter XavierInit(params int[] layerSizes) Parameters Type Name Description Int32 [] layerSizes The layer sizes of the Parameter object. Returns Type Description Parameter Zero(Int32[]) Returns a Paramter with weights and biases all zero. Declaration public static Parameter Zero(int[] layerSizes) Parameters Type Name Description Int32 [] layerSizes Returns Type Description Parameter"
  },
  "api/NeuralNetLearning.Maths.VectorFunctions.html": {
    "href": "api/NeuralNetLearning.Maths.VectorFunctions.html",
    "title": "Class VectorFunctions | NeuralNet",
    "keywords": "Class VectorFunctions Inheritance Object VectorFunctions Inherited Members Object.Equals(Object) Object.Equals(Object, Object) Object.GetHashCode() Object.GetType() Object.MemberwiseClone() Object.ReferenceEquals(Object, Object) Object.ToString() Namespace : NeuralNetLearning.Maths Assembly : NeuralNet.dll Syntax public static class VectorFunctions Methods BasisVector(Int32, Int32) Declaration public static Vector<double> BasisVector(int length, int oneIdx) Parameters Type Name Description Int32 length Int32 oneIdx Returns Type Description MathNet.Numerics.LinearAlgebra.Vector < Double > BasisVectors(Int32) Declaration public static Vector<double>[] BasisVectors(int length) Parameters Type Name Description Int32 length Returns Type Description MathNet.Numerics.LinearAlgebra.Vector < Double >[] IsFinite(Vector<Double>) Declaration public static bool IsFinite(Vector<double> vector) Parameters Type Name Description MathNet.Numerics.LinearAlgebra.Vector < Double > vector Returns Type Description Boolean Read(String) Declaration public static Vector<double> Read(string filepath) Parameters Type Name Description String filepath Returns Type Description MathNet.Numerics.LinearAlgebra.Vector < Double > StdNormal(Int32) Declaration public static Vector<double> StdNormal(int dim) Parameters Type Name Description Int32 dim Returns Type Description MathNet.Numerics.LinearAlgebra.Vector < Double > StdUniform(Int32) Declaration public static Vector<double> StdUniform(int dim) Parameters Type Name Description Int32 dim Returns Type Description MathNet.Numerics.LinearAlgebra.Vector < Double > Write(Vector<Double>, String) Declaration public static void Write(this Vector<double> vector, string filepath) Parameters Type Name Description MathNet.Numerics.LinearAlgebra.Vector < Double > vector String filepath"
  },
  "api/NeuralNetLearning.NeuralNet.html": {
    "href": "api/NeuralNetLearning.NeuralNet.html",
    "title": "Class NeuralNet | NeuralNet",
    "keywords": "Class NeuralNet A fully-connected neural network, with a customisable layer structure, Activation s, GradientDescender and CostFunction . Inheritance Object NeuralNet Inherited Members Object.Equals(Object) Object.Equals(Object, Object) Object.GetHashCode() Object.GetType() Object.MemberwiseClone() Object.ReferenceEquals(Object, Object) Object.ToString() Namespace : NeuralNetLearning Assembly : NeuralNet.dll Syntax public class NeuralNet Properties ActiveLayerCount The amount of active (i.e. non-input) layers. Declaration public int ActiveLayerCount { get; } Property Value Type Description Int32 LayerSizes An array containing the size of each layer, including the input layer, hidden layers, and activation layer Declaration public int[] LayerSizes { get; } Property Value Type Description Int32 [] Methods AverageCost(IEnumerable<(Vector<Double> input, Vector<Double> expectedOutput)>) Calculates the average of the error cost between each output vector calculated by the NeuralNet vs the corresponding expected output. Declaration public double AverageCost(IEnumerable<(Vector<double> input, Vector<double> expectedOutput)> testingPairs) Parameters Type Name Description IEnumerable < (T1, T2) < MathNet.Numerics.LinearAlgebra.Vector < Double >, MathNet.Numerics.LinearAlgebra.Vector < Double >>> testingPairs The list of (input, expected output) testing pairs. Returns Type Description Double Fit(IEnumerable<(Vector<Double> input, Vector<Double> expectedOutput)>, IEnumerable<(Vector<Double> input, Vector<Double> expectedOutput)>, Int32, Int32, Int32, Boolean) Fits the NeuralNet to the training data supplied in trainingPairs , using the NeuralNet's GradientDescender . Runs batch gradient descent. Declaration public void Fit(IEnumerable<(Vector<double> input, Vector<double> expectedOutput)> trainingPairs, IEnumerable<(Vector<double> input, Vector<double> expectedOutput)> testingPairs, int numEpochs, int batchSize = 256, int numAssessments = 15, bool batchUpdateInParallel = true) Parameters Type Name Description IEnumerable < (T1, T2) < MathNet.Numerics.LinearAlgebra.Vector < Double >, MathNet.Numerics.LinearAlgebra.Vector < Double >>> trainingPairs A (finite) IEnumerable of training data. Each element of trainingPairs is a tuple. The first element is the input to the NeuralNet. The second element is the corresponding output the NeuralNet will learn to produce. IEnumerable < (T1, T2) < MathNet.Numerics.LinearAlgebra.Vector < Double >, MathNet.Numerics.LinearAlgebra.Vector < Double >>> testingPairs A (finite) IEnumerable of testing data. The NeuralNet will not be trained on this data. This data will only be used to log performance to the console. Int32 numEpochs The number of times that batch gradient descent will be run on trainingPairs . Int32 batchSize The size of each batch that trainingPairs will be split into. Recommended values of batchSize range from 4 to 256. Int32 numAssessments Boolean batchUpdateInParallel If batchUpdateInParallel is true , the average gradient corresponding to each batch is computed in parallel. Reccommended for medium to high values of batchSize . Fit(IEnumerable<(Vector<Double> input, Vector<Double> expectedOutput)>, Int32, Int32, Boolean) Fits the NeuralNet to the training data supplied in trainingPairs , using the NeuralNet's GradientDescender . Runs batch gradient descent. Declaration public void Fit(IEnumerable<(Vector<double> input, Vector<double> expectedOutput)> trainingPairs, int numEpochs, int batchSize = 256, bool batchUpdateInParallel = true) Parameters Type Name Description IEnumerable < (T1, T2) < MathNet.Numerics.LinearAlgebra.Vector < Double >, MathNet.Numerics.LinearAlgebra.Vector < Double >>> trainingPairs A (finite) IEnumerable of training data. Each element of trainingPairs is a tuple. The first element is the input to the NeuralNet. The second element is the corresponding output the NeuralNet will learn to produce. Int32 numEpochs The number of times that batch gradient descent will be run on trainingPairs . Int32 batchSize The size of each batch that trainingPairs will be split into. Recommended values of batchSize range from 4 to 256. Boolean batchUpdateInParallel If batchUpdateInParallel is true , the average gradient corresponding to each batch is computed in parallel. Reccommended for medium to high values of batchSize . Predict(Vector<Double>) Calculates the output of the Neural Network for the vector input . Declaration public Vector<double> Predict(Vector<double> input) Parameters Type Name Description MathNet.Numerics.LinearAlgebra.Vector < Double > input Returns Type Description MathNet.Numerics.LinearAlgebra.Vector < Double > WriteToDirectory(String) Writes, in a human-readable format: Declaration public void WriteToDirectory(string directoryPath) Parameters Type Name Description String directoryPath The (relative or absolute) path of the directory to be written to."
  },
  "api/NeuralNetLearning.NeuralNetFactory.html": {
    "href": "api/NeuralNetLearning.NeuralNetFactory.html",
    "title": "Class NeuralNetFactory | NeuralNet",
    "keywords": "Class NeuralNetFactory A library class that holds various techniques in initialising a NeuralNet object. Inheritance Object NeuralNetFactory Inherited Members Object.Equals(Object) Object.Equals(Object, Object) Object.GetHashCode() Object.GetType() Object.MemberwiseClone() Object.ReferenceEquals(Object, Object) Object.ToString() Namespace : NeuralNetLearning Assembly : NeuralNet.dll Syntax public static class NeuralNetFactory Fields ActivationsFolder The name of the folder in which the Activation s used by a NeuralNet are recorded when writing a NeuralNet to a directory. Declaration public static readonly string ActivationsFolder Field Value Type Description String CostFolder The name of the file in which the CostFunction used by a NeuralNet is recorded when writing a NeuralNet to a directory. Declaration public static readonly string CostFolder Field Value Type Description String GradientDescenderFolder The name of the folder in which the GradientDescender used by a NeuralNet is recorded when writing a NeuralNet to a directory. Declaration public static readonly string GradientDescenderFolder Field Value Type Description String ParamsFolder The name of the folder in which the Parameter used by a NeuralNet is recorded when writing a NeuralNet to a directory. Declaration public static readonly string ParamsFolder Field Value Type Description String Methods OptimisedForRelu(IList<NeuralLayerConfig>) Returns a random NeuralNet that is optimised for the use of ReluActivation . Uses Adam gradient descent and mean-squared-error cost. Uses Kaiming He initialisation. Declaration public static NeuralNet OptimisedForRelu(IList<NeuralLayerConfig> layerStructure) Parameters Type Name Description IList < NeuralLayerConfig > layerStructure The configurations of the layer that the NeuralNet will conform to. Returns Type Description NeuralNet OptimisedForRelu(IList<NeuralLayerConfig>, GradientDescender, CostFunction) Returns a random NeuralNet that is optimised for the use of ReluActivation . Uses Kaiming He initialisation. Declaration public static NeuralNet OptimisedForRelu(IList<NeuralLayerConfig> layerStructure, GradientDescender gradientDescender, CostFunction cost) Parameters Type Name Description IList < NeuralLayerConfig > layerStructure The configurations of the layer that the NeuralNet will conform to. GradientDescender gradientDescender The gradient descender that the NeuralNet will use when executing gradient descent. CostFunction cost The cost function that the NeuralNet will use when executing gradient descent. Returns Type Description NeuralNet OptimisedForTanh(IList<NeuralLayerConfig>) Returns a random NeuralNet that is optimised for the use of TanhActivation . Uses Adam gradient descent and mean-squared-error cost. Uses Xavier initialisation . Declaration public static NeuralNet OptimisedForTanh(IList<NeuralLayerConfig> layerStructure) Parameters Type Name Description IList < NeuralLayerConfig > layerStructure The configurations of the layer that the NeuralNet will conform to. Returns Type Description NeuralNet OptimisedForTanh(IList<NeuralLayerConfig>, GradientDescender, CostFunction) Returns a random NeuralNet that is optimised for the use of TanhActivation . Uses Xavier initialisation . Declaration public static NeuralNet OptimisedForTanh(IList<NeuralLayerConfig> layerStructure, GradientDescender gradientDescender, CostFunction cost) Parameters Type Name Description IList < NeuralLayerConfig > layerStructure The configurations of the layer that the NeuralNet will conform to. GradientDescender gradientDescender The gradient descender that the NeuralNet will use when executing gradient descent. CostFunction cost The cost function that the NeuralNet will use when executing gradient descent. Returns Type Description NeuralNet OptimisedForTrainingData(IList<NeuralLayerConfig>, IEnumerable<Vector<Double>>, GradientDescender, CostFunction) Returns a random NeuralNet that is optimised for learning trainingData . Uses LSUV initialisation . Declaration public static NeuralNet OptimisedForTrainingData(IList<NeuralLayerConfig> layerStructure, IEnumerable<Vector<double>> trainingInputs, GradientDescender gradientDescender, CostFunction cost) Parameters Type Name Description IList < NeuralLayerConfig > layerStructure The configurations of the layer that the NeuralNet will conform to. IEnumerable < MathNet.Numerics.LinearAlgebra.Vector < Double >> trainingInputs The inputs of the training set which the NeuralNet will be optimised to learn. GradientDescender gradientDescender The gradient descender that the NeuralNet will use when executing gradient descent. CostFunction cost The cost function that the NeuralNet will use when executing gradient descent. Returns Type Description NeuralNet OptimisedForTrainingData(IList<NeuralLayerConfig>, IEnumerable<(Vector<Double> input, Vector<Double> expectedOutput)>) Returns a random NeuralNet that is optimised for learning trainingData . Uses Adam gradient descent and mean-squared-error cost. Uses LSUV initialisation . Declaration public static NeuralNet OptimisedForTrainingData(IList<NeuralLayerConfig> layerStructure, IEnumerable<(Vector<double> input, Vector<double> expectedOutput)> trainingData) Parameters Type Name Description IList < NeuralLayerConfig > layerStructure The configurations of the layer that the NeuralNet will conform to. IEnumerable < (T1, T2) < MathNet.Numerics.LinearAlgebra.Vector < Double >, MathNet.Numerics.LinearAlgebra.Vector < Double >>> trainingData The training set which the NeuralNet will be optimised to learn. Returns Type Description NeuralNet OptimisedForTrainingData(IList<NeuralLayerConfig>, IEnumerable<(Vector<Double> input, Vector<Double> expectedOutput)>, GradientDescender, CostFunction) Returns a random NeuralNet that is optimised for learning trainingData . Uses LSUV initialisation . Declaration public static NeuralNet OptimisedForTrainingData(IList<NeuralLayerConfig> layerStructure, IEnumerable<(Vector<double> input, Vector<double> expectedOutput)> trainingData, GradientDescender gradientDescender, CostFunction cost) Parameters Type Name Description IList < NeuralLayerConfig > layerStructure The configurations of the layer that the NeuralNet will conform to. IEnumerable < (T1, T2) < MathNet.Numerics.LinearAlgebra.Vector < Double >, MathNet.Numerics.LinearAlgebra.Vector < Double >>> trainingData The training set which the NeuralNet will be optimised to learn. GradientDescender gradientDescender The gradient descender that the NeuralNet will use when executing gradient descent. CostFunction cost The cost function that the NeuralNet will use when executing gradient descent. Returns Type Description NeuralNet ReadFromDirectory(String) Reads the NeuralNet object that has been written to directoryPath using the function WriteToDirectory(String) . The returned NeuralNet has equivalent Parameter values, Activation , GradientDescender and CostFunction compared to the written NeuralNet . Declaration public static NeuralNet ReadFromDirectory(string directoryPath) Parameters Type Name Description String directoryPath The (absolute or relative) path to which a Neural Net has been written. Returns Type Description NeuralNet"
  },
  "api/NeuralNetLearning.Serialization.html": {
    "href": "api/NeuralNetLearning.Serialization.html",
    "title": "Namespace NeuralNetLearning.Serialization | NeuralNet",
    "keywords": "Namespace NeuralNetLearning.Serialization Classes SerializableHyperParameter"
  },
  "api/NeuralNetLearning.Serialization.SerializableHyperParameter.html": {
    "href": "api/NeuralNetLearning.Serialization.SerializableHyperParameter.html",
    "title": "Class SerializableHyperParameter | NeuralNet",
    "keywords": "Class SerializableHyperParameter Inheritance Object Attribute SerializableHyperParameter Inherited Members Attribute.Equals(Object) Attribute.GetCustomAttribute(Assembly, Type) Attribute.GetCustomAttribute(Assembly, Type, Boolean) Attribute.GetCustomAttribute(MemberInfo, Type) Attribute.GetCustomAttribute(MemberInfo, Type, Boolean) Attribute.GetCustomAttribute(Module, Type) Attribute.GetCustomAttribute(Module, Type, Boolean) Attribute.GetCustomAttribute(ParameterInfo, Type) Attribute.GetCustomAttribute(ParameterInfo, Type, Boolean) Attribute.GetCustomAttributes(Assembly) Attribute.GetCustomAttributes(Assembly, Boolean) Attribute.GetCustomAttributes(Assembly, Type) Attribute.GetCustomAttributes(Assembly, Type, Boolean) Attribute.GetCustomAttributes(MemberInfo) Attribute.GetCustomAttributes(MemberInfo, Boolean) Attribute.GetCustomAttributes(MemberInfo, Type) Attribute.GetCustomAttributes(MemberInfo, Type, Boolean) Attribute.GetCustomAttributes(Module) Attribute.GetCustomAttributes(Module, Boolean) Attribute.GetCustomAttributes(Module, Type) Attribute.GetCustomAttributes(Module, Type, Boolean) Attribute.GetCustomAttributes(ParameterInfo) Attribute.GetCustomAttributes(ParameterInfo, Boolean) Attribute.GetCustomAttributes(ParameterInfo, Type) Attribute.GetCustomAttributes(ParameterInfo, Type, Boolean) Attribute.GetHashCode() Attribute.IsDefaultAttribute() Attribute.IsDefined(Assembly, Type) Attribute.IsDefined(Assembly, Type, Boolean) Attribute.IsDefined(MemberInfo, Type) Attribute.IsDefined(MemberInfo, Type, Boolean) Attribute.IsDefined(Module, Type) Attribute.IsDefined(Module, Type, Boolean) Attribute.IsDefined(ParameterInfo, Type) Attribute.IsDefined(ParameterInfo, Type, Boolean) Attribute.Match(Object) Attribute.TypeId Object.Equals(Object, Object) Object.GetType() Object.MemberwiseClone() Object.ReferenceEquals(Object, Object) Object.ToString() Namespace : NeuralNetLearning.Serialization Assembly : NeuralNet.dll Syntax [AttributeUsage(AttributeTargets.Field, AllowMultiple = false)] public class SerializableHyperParameter : Attribute Constructors SerializableHyperParameter(String) Declaration public SerializableHyperParameter(string name) Parameters Type Name Description String name Fields Name Declaration public readonly string Name Field Value Type Description String"
  },
  "articles/activation.html": {
    "href": "articles/activation.html",
    "title": "Activation | NeuralNet",
    "keywords": "Activation The Activation class represents an activation function that is applied in NeuralNet . Use in initialising a NeuralNet When initialising a NeuralNet using NeuralNetFactory , an Activation is supplied to each Hidden Layer and Output Layer . To see an example, click here . Provided Activation s There are four Activation s provided by default: ReLU Sigmoid Tanh Identity Softmax ReLU activation ReLU activation is provided through ReluActivation . ReluActivation has a leak of zero by default, but can be given a leak value through the optional argument leak . ReLU activation works well for most projects. If you are unsure of what activation function to use, ReLU activation (with little or no leak) is usually a good option. The neural layers in initialising a NeuralNet can be set to use ReluActivation by setting the layer structure to, for example: List<NeuralLayerConfig> layerStructure = new () { ... new HiddenLayer(size: 100, activation: new ReluActivation()), new HiddenLayer(size: 100, activation: new ReluActivation(leak: 0.01)), ... }; Sigmoid activation Sigmoid activation (here, the logistic sigmoid) is provided through SigmoidActivation . SigmoidActivation takes no arguments. The outputs of the sigmoid activation function lie between 0 and 1. This range of values has lead to sigmoid activation often being used in statistics. The neural layers in initialising a NeuralNet can be set to use SigmoidActivation by setting the layer structure to, for example: List<NeuralLayerConfig> layerStructure = new () { ... new HiddenLayer(size: 100, activation: new SigmoidActivation()), ... }; Tanh activation Tanh activation is provided through TanhActivation . TanhActivation takes no arguments. Tanh activation can be thought of as rescaling sigmoid activation so that the output lies between -1 and 1. The fact that tanh activation maps zero to zero gives tanh superior properties in gradient descent compared to sigmoid activation (see here ). The neural layers in initialising a NeuralNet can be set to use TanhActivation by setting the layer structure to, for example: List<NeuralLayerConfig> layerStructure = new () { ... new HiddenLayer(size: 100, activation: new TanhActivation()), ... }; Identity activation The identity function , also known in machine learning as \"linear activation\", is provided through IdentityActivation . The identity function does not process its input: it simply returns whatever input was given to it. If you do not want to force your output values to lie in a particular range, then you should use IdentityActivation . IdentityActivation is used in OutputLayer by default. The output layer in initialising a NeuralNet can be set to use IdentityActivation by setting the layer structure to: List<NeuralLayerConfig> layerStructure = new () { ... new OutputLayer(size: 100) }; or, more explicitly: List<NeuralLayerConfig> layerStructure = new () { ... new OutputLayer(size: 100, activation: new IdentityActivation()) }; Softmax activation Softmax activation is provided through SoftmaxActivation . SoftmaxActivation takes no arguments. Softmax activation returns a vector with each entry between 0 and 1. Put simply, the i th output entry measures how large the i th input entry is compared to all the other input entries, as a ratio between 0 and 1. More precisely: the greater the input entry, the closer the output entry is to 1 all the output entries add to 1 This makes softmax activation useful to apply to the output layer if the output vector should be a vector of ratios or a vector of probabilities. The output layer in initialising a NeuralNet using NeuralNetFactory can be set to use SoftmaxActivation by by setting the layer structure to: List<NeuralLayerConfig> layerStructure = new () { ... new OutputLayer(size: 100, activation: new SoftmaxActivation()) };"
  },
  "articles/cost-function.html": {
    "href": "articles/cost-function.html",
    "title": "Cost Function | NeuralNet",
    "keywords": "Cost Function The CostFunction class represents a cost function that is used in fitting a NeuralNet . Use in initializing a NeuralNet When initializing a NeuralNet using NeuralNetFactory a cost function is supplied at the final step . Provided cost functions There are three cost functions provided by default: Mean Squared Error Huber cost Cross Entropy Mean Squared Error Mean squared error is provided by MSECost . Mean squared error is the simplest of the three provided cost functions. It is a good cost function to use when the output values are not forced to lie in a small range, i.e. when using IdentityActivation . When initialising a NeuralNet , the cost function can be set to MSECost by setting the cost function to CostFunction costFunction = new MSECost(); Huber cost Huber cost is provided by HuberCost . Huber cost is an adaptation of mean squared error where the cost is linear, instead of quadratic, when the error is larger than a given value. This means that Huber cost is less affected by extreme errors (outliers) than mean squared error. To use Huber cost, you need to set the size of the error for which Huber cost becomes linear. Set this value, called outlierBoundary , to how large of an error you wish to treat as an outlier in your project. When initialising a NeuralNet , the cost function can be set to MSECost by setting the cost function to, for example (with an outlier boundary of 1): CostFunction costFunction = new HuberCost(outlierBoundary: 1.0); Cross Entropy Cross entropy is provided by CrossEntropyCost . Cross entropy measures the error in learning probabilities. If you are using CrossEntropyCost , it is reccommended to apply softmax activation to your output layer. This will ensure that your output vector is a vector of probabilities. Warning In using cross entropy cost, the expected output vector must be a vector of probabilities: i.e. its entries must be between 0 and 1 . Supplying an expected output vector with non-positive entries will cause NaN s to appear. When initialising a NeuralNet , the cost function can be set to MSECost by setting the cost function to, for example (with an outlier boundary of 1): CostFunction costFunction = new CrossEntropyCost();"
  },
  "articles/creating-neural-network.html": {
    "href": "articles/creating-neural-network.html",
    "title": "Creating your first Neural Network | NeuralNet",
    "keywords": "Creating your first Neural Network This article will show you how to initialise and train your first neural network. Here we'll create our first neural network. The neural network we're creating will do as simple a task as possible, while still being (technically) impressive: we'll teach it how to square numbers! Although our goal here is kind of boring, it won't get in the way of the process shown here, which will apply to any other neural network you make. This example was adapted from a question on stackoverflow that I stumbled across. I recommend reading through the question and top answer. They address the same problem using the same method as this article, with helpful explanatory comments. First, we need to prepare our training data . Then, we initialise and then train our neural network. Finally, we'll round off by seeing how well our neural network performs . Preparing our data A NeuralNet is, fundamentally, a mathematical object. It takes in vectors as inputs and predicts the appropriate vectors to output. By giving a NeuralNet many sample input vectors paired with the expected vectors the NeuralNet should ideally output, the NeuralNet \"learns\" to produce increasingly accurate output vectors. This process is known as fitting . Since all we want our NeuralNet to do is square numbers, the data we are working with is very simple. Our inputs are random numbers between -50 and 50, stored in a Vector<double> of length 1. Our outputs are the corresponding inputs squared. We'll start by writing a function that'll give us such input-output pairs. List<(Vector<double>, Vector<double>)> InputOutputPairs(int numPairs) { List<(Vector<double> input, Vector<double> expectedOutput)> pairs = new(capacity: numPairs); for (int i = 0; i < numPairs; i++) { Vector<double> input = 50 * Vector<double>.Build.Random(length: 1); Vector<double> expectedOutput = input.PointwisePower(2); pairs.Add((input, expectedOutput)); } return pairs; } Initialising our Neural Network Before we start training, we need to create a \"blank\" NeuralNet that is ready to learn. We use NeuralNetFactory to create a NeuralNet that is optimised for our project. Layer Structure First, we have to decide on our neural network's layer structure. In this project, we take a single number as input and output a single number, so our input layer and output layer will both have a size of 1. To give our neural network some complexity, we'll also have two hidden layers, both of size 8. These hidden layers will use ReLU activation : an activation which works well for a wide range of projects. Overall, our layer structure is: - an input layer of size 1 - a hidden layer of size 8 using ReLU activation - a hidden layer of size 8 using ReLU activation - an output layer of size 1 We'll package the structure of each layer into an InputLayer , HiddenLayer or OutputLayer record, all three of which inherit from NeuralLayerConfig . The structure of our neural network is represented by a List<NeuralLayerConfig> : List<NeuralLayerConfig> layerStructure = new() { new InputLayer(size: 1), new HiddenLayer(size: 8, activation: new ReluActivation()), new HiddenLayer(size: 8, activation: new ReluActivation()), new OutputLayer(size: 1) }; Initialising using NeuralNetFactory The NeuralNetFactory library class will create a NeuralNet that is optimised to learn for our project. Since we are using ReLU activation, we will make a NeuralNet , using our layer structure, that is optimised to learn with ReLU: NeuralNet neuralNet = NeuralNetFactory.OptimisedForRelu(layerStructure); Training our Neural Network To train our neural network, we supply neuralNet with 8000 training data to fit to. We will also supply a separate collection of 2000 testing data. The neural network will not train to fit to this data: instead, the data will be used to periodically assess neuralNet 's performace as it learns. List<(Vector<double>, Vector<double>)> trainingData = InputOutputPairs(8000); List<(Vector<double>, Vector<double>)> testingData = InputOutputPairs(2000); The neural network will learn from each pair in trainingData once every epoch. For this project, we will set the number of epochs to 15,000. neuralNet.Fit(trainingData, testingData, numEpochs: 15000); Fitting the neural network to trainingData took around 11 minutes on my mid-range laptop. Seeing how well our Neural Network performs To see how good neuralNet is at squaring numbers, let's see neuralNet 's performance on ten random inputs, comparing neuralNet 's predicted values with the true values: foreach ((Vector<double> input, Vector<double> expectedOutput) in InputOutputPairs(10)) { Vector<double> predictedOutput = neuralNet.Predict(input); Console.WriteLine($\"{input[0]} --> \\t {predictedOutput[0]} \\t (expected: {expectedOutput[0]})\"); } (Feel free to add your own formatting.) My neuralNet performed as follows. Yours should perform similarly. Performance of `neuralNet` with 10 randomly chosen inputs, compared with the expected outputs. It's safe to say that neuralNet has roughly understood how squaring works: not only is neuralNet fairly accurate numerically, but it also seems to do as well with negative inputs as positive inputs. However, it struggles with squaring small numbers: e.g. 9.42 and 9.56 both get \"squared\" to 39.37 . Ironing out problems like these will require more customisation and experimentation. To start, explore the different options in NeuralNetFactory and NeuralNet . Or, make yourself more confident with what you've already learned by creating a NeuralNet that learns a different function: perhaps f(x) = x^3 or f(x) = sin(x) rather than f(x) = x^2 ."
  },
  "articles/gradient-descender.html": {
    "href": "articles/gradient-descender.html",
    "title": "Gradient Descender | NeuralNet",
    "keywords": "Gradient Descender The GradientDescender class represents a gradient descent algorithm. Use in initialising a NeuralNet When initialising a NeuralNet , the gradient descender is passed to NeuralNetFactory . Provided Gradient Descenders There are two gradient descenders provided by default: Adam and Stochastic gradient descent. Adam Gradient Descender Adam gradient descent is the go-to gradient descent algorithm for most projects. It is a complex algorithm that uses a combination of many different learning rates, which each speed up or slow down independently while learning. To create an AdamGradientDescender with default settings, simply run AdamGradientDescender gradientDescender = new(); This uses the settings reccommended by the creators of the algorithm. These settings work well for most projects. If you would like to set your own values, however, specify in any of the three hyper-parameters like so: AdamGradientDescender gradientDescender = new(learningRate: ..., momentumDecay: ..., varianceDecay: ...); With respect to the original article : - learningRate corresponds to  - momentumDecay corresponds to 1 - varianceDecay corresponds to 2 Stochastic Gradient Descender Stochastic gradient descent (also known as vanilla mini-batch gradient descent ) is the simplest gradient descent algorithm. Adam gradient descent may be faster than stochastic gradient descent in most cases, but stochastic gradient descent is a safe fall-back if you suspect adam gradient descent is not suited for your project. For example, if you think a learning rate of 0.001 is best for your project, you can create a StochasticGradientDescender by StochasticGradientDescender gradientDescender = new(learningRate: 0.001); Stochastic gradient descent is far simpler than Adam gradient descent. Instead of dynamically speeding up or slowing down learning rates, stochastic gradient descent sticks with one single learning rate throughout the learning process. This means that picking the right learning rate is crucial, and will depend highly on your own project. Making your own Gradient Descender (Technical) If you have a gradient descent algorithm in mind, you can make your own gradient descender class. To work with NeuralNet , and in particular, serialization, your class will have to: - inherit from the abstract class GradientDescender - implement all the hyper-parameters you need as fields - annotate all the hyper-parameters you need with SerializableHyperParameter - have a default constructor - implement Parameter GradientDescentStep(Parameter gradient) You will need to have read Parameter and SerializableHyperParameter before reading this. Let's implement momentum gradient descent as an example: First, we import the required namespaces for Parameter , GradientDescender and SerializableHyperParameter respectively. using NeuralNetLearning.Maths; using NeuralNetLearning.Maths.GradientDescent; using NeuralNetLearning.Serialization; public class MomentumGradientDescender : GradientDescender { Next, we mark all the hyper-parameters that we want to be able to save and read in with SerializableHyperParameter . These hyper-parameters should be enough to fully reconstruct our gradient descender. In this example, _learningRate corresponds to  in the momentum gradient descent description, and _momentumRate corresponds to . [SerializableHyperParameter(\"learning rate\")] private readonly double _learningRate; [SerializableHyperParameter(\"momentum rate\")] private readonly double _momentumRate; [SerializableHyperParameter(\"past step\")] private Parameter _pastStep = null; We then create our constructor for these fields. A default constructor is also required for the automatic serialization. public MomentumGradientDescender(double learningRate, double momentumRate) { _learningRate = learningRate; _momentumRate = momentumRate; } private MomentumGradientDescender() : this(learningRate: 0.01, momentumRate: 0.9) { } Finally, we implement the momentum gradient descent algorithm in Parameter GradientDescentStep(Parameter gradient) . The function takes in the cost gradient of the weights and biases as a Parameter . This Parameter holds all the cost gradients of the corresponding weight/bias entries. GradientDescentStep(...) returns the step that should be made in parameter space to reduce cost. In other words, the return value will be added to the Parameter holding the weights and biases of the NeuralNet to reduce cost. public override Parameter GradientDescentStep(Parameter gradient) { if (_pastStep == null) _pastStep = ParameterFactory.Zero(gradient.LayerSizes); Parameter step = -_learningRate * gradient + _momentumRate * _pastStep; _pastStep = step; return step; // in the NeuralNet class: parameter += step; } }"
  },
  "articles/intro.html": {
    "href": "articles/intro.html",
    "title": "Introduction | NeuralNet",
    "keywords": "Introduction NeuralNetLearning is a neural network library that is great both for a beginner looking to get started quickly, and a technical expert wishing to implement their own features. It is built on the Vector<double> and Matrix<double> types in Math.NET Numerics . Creating your first Neural Network To begin, read the article on creating your first neural network . This will teach you how to make a very basic neural network, introducing you to all the key tools and concepts. Next Steps Once you are comfortable with the basics, start exploring the features in NeuralNetFactory and NeuralNet . This will introduce you to advanced concepts that have been overlooked in the previous article, such as GradientDescender and CostFunction . Outside Research Machine learning is a heavily researched and documented field, and there are lots of resources to help you learn more. Below are a list of links that taught me the technical details behind machine learning: Very brief overview of what a neural network is: Why do Neural Networks Need an Activation Function? (up to \"What does a Neuron do?\") The mathematics behind machine learning: 3blue1brown, machine learning playlist An overview of cost functions and gradient descent: Machine learning fundamentals (I): Cost functions and gradient descent Activation functions explained: Understanding Activation Functions in Neural Networks Various Gradient Descent methods compared: An overview of gradient descent optimisation algorithms"
  },
  "articles/neural-layer-config.html": {
    "href": "articles/neural-layer-config.html",
    "title": "Neural Layer Configuration | NeuralNet",
    "keywords": "Neural Layer Configuration When creating a NeuralNet from NeuralNetFactory , the layer structure is set by passing an IList<NeuralLayerConfig> . This IList<NeuralLayerConfig> must begin with an InputLayer and end with an OutputLayer . For example, List<NeuralLayerConfig> layerStrucutre = new () { new InputLayer(size: 100), new HiddenLayer(size: 70, activation: new ReluActivation(leak: 0.01)), new HiddenLayer(size: 30, activation: new ReluActivation(leak: 0.01)), new OutputLayer(size: 10, activation: new SoftmaxActivation()) }; ... NeuralNet net = NeuralNetFactory.OptimisedForRelu(layerStrucutre, ... ); Vector<double> inputVector = Vector<double>.Build.Dense(length: 100, value: 0); // length of input vector must match `size` supplied to `InputLayer` Vector<double> outputVector = net.GetOutputVector(inputVector); // `outputVector` is of length 10, since 10 is the value of `size` supplied to `OutputLayer` NeuralLayerConfig NeuralLayerConfig is the base record for InputLayer HiddenLayer OutputLayer Input Layer InputLayer stores the size of the first (i.e. input) layer. Once the NeuralNet is created, InputLayer.Size will be the size of the input vectors accepted by the NeuralNet . Hidden Layer HiddenLayer stores the size and activator used by a hidden layer. These are intermediary layers. They are not required, but they give complexity to the Neural Network. Output Layer OutputLayer stores the size and activator used by the final (i.e. output) layer. Once the NeuralNet is created, OutputLayer.Size will be the size of the output vectors returned by the NeuralNet , and OutputLayer.Activation will be applied to these output vectors. Technical Note: Note that the IList<NeuralLayerConfig> does not represent how NeuralNet works internally. In creating a NeuralNet from NeuralNetFactory , the IList<NeuralLayerConfig> is purely used to initialise a Parameter object of the right size and to supply the right Activation[] to the NeuralNet . Once this is done, the NeuralNet uses the Parameter object and Activation[] array."
  },
  "articles/neural-net.html": {
    "href": "articles/neural-net.html",
    "title": "Neural Net | NeuralNet",
    "keywords": "Neural Net A NeuralNet takes a Vector<double> as input and predicts the appropriate Vector<double> to output. By giving NeuralNet a training data set, consisting of pairs of sample inputs with the correct output, the NeuralNet will learn to produce more accurate outputs. Not only should the NeuralNet` perform accuately with the training data given, but it should also perform just as accuately with similar inputs that it has not been trained on. Creating a Blank NeuralNet See NeuralNetFactory for how to create a \"blank\" NeuralNet that is ready to train. Preparing Training Data for a NeuralNet The NeuralNet will learn how to produce approximately the right output for a given input. Thus, you will need to prepare your data as a list of inputs paired with the corresponding output you want to be produced. Because a NeuralNet is a mathematical object, each input and output will need to be a Vector<double> . Every input vector must have the same length, and every output vector must have the same length. The output vectors can have different lengths to the input vectors, however. If you want your NeuralNet to input or output a single number, you must use Vector<double> s of length 1. See creating your first neural network for a detailed example. Fitting a NeuralNet to Training Data Once you have prepared your training data into a collection of paired input and output vectors, use NeuralNet.Fit(...) to train the NeuralNet . This will repeatedly adjust the neural network so that its predicted output vectors are increasingly closer to the expected output vectors. List<(Vector<double>, Vector<double>)> trainingData = ... ; // see above neuralNet.Fit(trainingData, numEpochs: 50000); There are three arguments to configure the training: Number of Epochs The NeuralNet trains from the entire data set once every epoch. In other words, the amount of epochs is the amount of times the NeuralNet learns from each data point in traningData . Up to a point, the more times the NeuralNet learns from each data point, the more accurate the NeuralNet will be. However, if the number of epochs is higher than necessary, the NeuralNet will try \"too hard\" to match the input data exactly, and start to lose its ability to perform well on similar data that it has not seen. This is called over-fitting . It is important to pick a value of numEpochs that is high enough for the NeuralNet to learn well from each data point, but not too high that the NeuralNet starts to over-fit. Read Measuring Performance while Training for more information. Batch Size NeuralNet.Fit(...) performs batch gradient descent : instead of learning from each data point one at a time, the NeuralNet learns from multiple data points at once, the amount of which is the batch size. Reccommended values range from 4 to 256, with 256 being the default value. Batch Updating in Parallel If this options is enabled, the NeuralNet learns from each data point in a given batch in parallel. ( Technical note : the NeuralNet calculates the cost gradient for each data point in the batch in parallel, then learns from the average of the cost gradients sequentially.) This is done for performance gains, which will be greater the higher the Batch Size . Measuring Performance Average Cost You can measure a NeuralNet 's performance using NeuralNet.AverageCost(...) . When fitting to training data, the neural network seeks to decrease the cost quantifying the error in the neural network's predicted outputs versus the expected outputs in the training data. NeuralNet.AverageCost(...) returns the average cost of the neural network's error in the supplied testing data. NeuralNet neuralNet = ... ; List<(Vector<double> input, Vector<double> expectedOutput)> testingData = ... ; double averageCost = neuralNet.AverageCost(testingData); Warning To get a meaningful indication of how the neural network performs, supply AverageCost(...) with testing data that is different from the training data This way, the average cost will measure how well the neural network generalises to data it has not trained on Measuring Cost while Training You can assess a NeuralNet 's performance while training by supplying testing data to NeuralNet.Fit(...) . This will assess the NeuralNet 's performance by writing the average cost of the NeuralNet on the testing data periodically while training. NeuralNet neuralNet = ... ; List<(Vector<double>, Vector<double>)> trainingData = ... ; List<(Vector<double>, Vector<double>)> testingData = ... ; neuralNet.Fit(trainingData, testingData); The amount of times the average cost is written to the console can be configured by adjusting numAssessments . This number is 15 by default. NeuralNet neuralNet = ... ; List<(Vector<double>, Vector<double>)> trainingData = ... ; List<(Vector<double>, Vector<double>)> testingData = ... ; neuralNet.Fit(trainingData, testingData, numAssessments: 20); Predicting Output Vectors Given an input Vector<double> , the NeuralNet predicts the appropriate output Vector<double> . Once the NeuralNet has sufficiently fitted to training data , you can expect the predicted output to be accurate, but not a complete match. The following example uses a NeuralNet with an input layer of size 10 and an output layer of size 5. The example shows the NeuralNet 's predicted output on three random input vectors. List<NeuralLayerConfig> layerStructure = new() { new InputLayer(size: 10), ... new OutputLayer(size: 5) }; NeuralNet neuralNet = NeuralNetFactory.OptimisedForRelu(layerStructure, ...); neuralNet.Fit(...); for (int i = 0; i < 3; i++) { Vector<double> input = Vector<double>.Build.Random(length: 10); Vector<double> predictedOutput = neuralNet.Predict(input); // is of length 5 Console.WriteLine($\"input: {input}\"); Console.WriteLine($\"predicted output: {predictedOutput}\"); Console.WriteLine(); }"
  },
  "articles/neural-net-factory.html": {
    "href": "articles/neural-net-factory.html",
    "title": "Neural Net Factory | NeuralNet",
    "keywords": "Neural Net Factory The NeuralNetFactory class makes it easy to initialise a NeuralNet for most practical purposes. Starting From Scratch Here, we will initialise a NeuralNet that is ready to learn how to square numbers, while showing the other options along the way. Our NeuralNet 's input will be a vector containing a single number to square, between -50 and 50. The output will be a vector containing a single number that is, approximately, the input number squared. Layer Structure First, decide on the structure you want your layers to have. This is done by creating a list of NeuralLayerConfig . For example, to create our \"x squared\" neural net described above , we will need the input and output layers to both be of size 1. The rest is up to you, but a good structure to go for is: an input layer of size 1 a hidden layer of size 8, using ReLU activation a hidden layer of size 8, using ReLU activation an output layer of size 1, using no activation at all (that is, identity activation ) To do this, create the following list: List<NeuralLayerConfig> layerStructure = new () { new InputLayer(size: 1), new HiddenLayer(size: 8, activation: new ReluActivation()), new HiddenLayer(size: 8, activation: new ReluActivation()), new OutputLayer(size: 1, activation: new IdentityActivation()) }; Gradient Descender Next, decide on which method of gradient descent you wish to use. Adam gradient descent with default arguments is reccomended for most training data sets, and is used in this example: GradientDescender gradientDescender = new AdamGradientDescender(); Cost Function Next, decide on which cost function you wish to use. This will depend heavily on what kind of data you wish to learn. Here, since our outputs lie in a wide range (between -2500 and 2500), mean squared error is used: CostFunction cost = new MSECost(); Creating your Neural Network There are various ways of best initializing a NeuralNet , depending on which activators it will use and what training data it will be learning. Optimising for ReLU learning If your layer structure mostly uses ReLU activation (such as in our example), you can create a Neural Net that is optimised for learning with ReLU: NeuralNet neuralNet = NeuralNetFactory.OptimisedForRelu(layerStructure, gradientDescender, cost); This is it: our NeuralNet has been created, ready to learn how to square numbers! Optimising for tanh learning If, however, your layer structure mostly uses tanh activation, you can create a NeuralNet that is optimised for learning with tanh: NeuralNet neuralNet = NeuralNetFactory.OptimisedForTanh(layerStructure, gradientDescender, cost); Optimising for learning a particular data set A more recent option is to create a NeuralNet that is optimised for learning some particular training data. When optimising, this will take into account the NeuralNet's layer structure and activators. However, it will not take into account the gradient descent method or cost function used. IEnumerable<(Vector<double> input, Vector<double> desiredOutput)> trainingData = ... ; NeuralNet neuralNet = NeuralNetFactory.OptimisedForTrainingData(layerStructure, trainingData, gradientDescender, cost); Since the method used in NeuralNetFactory.OptimisedForTrainingData() only uses the input vectors in the training data, there is an overload that simply takes the training input vectors: IEnumerable<Vector<double>> trainingInputs = ... ; NeuralNet neuralNet = NeuralNetFactory.OptimisedForTrainingData(layerStructure, trainingInputs, gradientDescender, cost); Reading a NeuralNet from a directory If you have previously written a NeuralNet to a directory using NeuralNet.WriteToDirectory() , then NeuralNetFactory.ReadFromDirectory() will load the NeuralNet back in. NeuralNet.ReadFromDirectory() returns a new NeuralNet with identical: Parameter (so, identical weights, biases and layer structure) Activator s applied to their corresponding layers GradientDescender CostFunction to the original NeuralNet that was written to the directory: NeuralNet neuralNet = ... ; neuralNet.Fit(...); neuralNet.WriteToDirectory(\"../../neural-net-state\"); NeuralNet read = NeuralNetFactory.ReadFromDirectory(\"../../neural-net-state\"); // `read` now has the same internal state as `neuralNet`."
  },
  "articles/parameter.html": {
    "href": "articles/parameter.html",
    "title": "Parameter (Technical) | NeuralNet",
    "keywords": "Parameter (Technical) The Parameter object is used internally by NeuralNet . Parameter encapsulates the weight matrices and the bias vectors that correspond to each layer. Mathematical Operations Through supporting basic mathematical operations, such as addition, scalar multiplication and component-wise operations, Parameter can be treated like a single vector in calculations. This makes it easy to implement custom gradient descent algorithms. Example: Gradient Descent in NeuralNet Here is an overview of how Parameter is used in NeuralNet to minimise cost through gradient descent. The parameter object param stores the weights and biases used in the NeuralNet . These are used to calculate the layers. In each gradient descent step, gradient stores the cost gradients of the corresponding entries in param . More explicitly, the i th entry in gradient is the cost gradient of the i th weight/bias entry in param . step is then added to param to adjust the weights/biases and minimise cost. The gradient descent algorithm is contained in gradientDescender . For instance, gradientDescender.GradientDescentStep(...) could use stochasic gradient descent, adam gradient descent, or any other gradient descent algorithm. To find out more, read Gradient Descender . public class NeuralNet { private Parameter param = ... ; // holds the weights and biases private GradientDescender gradientDescender = ... ; ... public void Fit(...) { Parameter gradient = ... ; // holds the cost gradients of the corresponding entries in `param` Parameter step = gradientDescender.GradientDescentStep(gradient); param += step; } } The way Parameter s are used here abstracts away weight matrices and bias vectors. Their syntax reads like single vectors, making the algorithm clearer. Example: Stochastic Gradient Descent Here is an overview of a possible definition of GradientDescender.GradientDescentStep(...) . This example uses the stochastic gradient descent algorithm . Following this algorithm, the cost gradient is simply multiplied by a scalar learning rate. public class StochasticGradientDescender : GradientDescender { ... private double _learningRate = 0.001; ... public Parameter GradientDescentStep(Parameter gradient) { Parameter step = -_learningRate * gradient; return step; } } (Some implementation details have been omitted: to see these, read Gradient Descender .) Again, the usage of Parameter objects abstracts away the weight matrices and bias vectors that they contain. See the Parameter API for a list of mathematical operations, and Gradient Descender for examples on this usage."
  },
  "articles/serializable-hyper-parameter.html": {
    "href": "articles/serializable-hyper-parameter.html",
    "title": "Serializable Hyper Parameter (Technical) | NeuralNet",
    "keywords": "Serializable Hyper Parameter (Technical) SerializableHyperParameter is an annotation used in reading and writing fields used in Activation , Cost Function and Gradient Descender implementations. If you want to make your own custom implementation of either of the three, for your implementation to support serialization, you will need to annotate your fields with SerializableHyperParameter . Currently, SerializableHyperParameter only supports some mathematical types: namely, double int bool Parameter . Example: Implementing RProp Gradient Descent The RProp gradient descent algorithm uses three hyper-parameters: the minimum step size ( double _minStepSize ) the maximum step size ( double _maxStepSize ) the previous cost gradient ( Parameter _prevGradient ) Let's make these hyper-parameters serializable: public RPropGradientDescender : GradientDescender { [SerializableHyperParameter(\"min step size\")] private readonly double _minStepSize = 0.001; [SerializableHyperParameter(\"max step size\")] private readonly double _maxStepSize = 0.1; [SerializableHyperParameter(\"previous gradient\")] private Parameter _prevGradient = null; ... } Assume we implement the rest of RPropGradientDescender according to the steps in GradientDescender . If we use RPropGradientDescender in a NeuralNet and write the NeuralNet to a directory, the following output is produced in the \"gradient descender\" folder: Contents of the gradient descent folder. Contents of the hyper-parameter.txt file. Contents of the hyper-parameter.txt file."
  },
  "index.html": {
    "href": "index.html",
    "title": "Introduction | NeuralNet",
    "keywords": "Introduction NeuralNetLearning is a neural network library that is great both for a beginner looking to get started quickly, and technical experts wishing to implement their own features. It is built on the Vector<double> and Matrix<double> types in Math.NET Numerics ."
  }
}